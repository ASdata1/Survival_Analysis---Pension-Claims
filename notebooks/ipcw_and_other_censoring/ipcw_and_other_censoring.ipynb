{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa078ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from lifelines import KaplanMeierFitter\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8fc51d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensure results folder exists\n",
    "os.makedirs(\"data/censoring_methods\", exist_ok=True)\n",
    "\n",
    "# load synthetic data\n",
    "df = pd.read_csv(\"C:\\\\Users\\\\04ama\\\\OneDrive\\\\pension survival analysis\\\\notebooks\\\\Data generation\\\\synthetic_survival_data.csv\")\n",
    "\n",
    "print(\"Censoring rate:\", 1 - df[\"event_observed\"].mean())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1be24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_zero = df.copy()\n",
    "df_zero[\"method\"] = \"zero\"\n",
    "df_zero.to_csv(\"data/censoring_methods/data_zero.csv\", index=False)\n",
    "print(\"Saved:\", \"data/censoring_methods/data_zero.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a04578",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ----------------- 1. SPLIT DATA -----------------\n",
    "df_train, df_test = train_test_split(\n",
    "    df, test_size=0.3, random_state=42, stratify=df[\"event_observed\"]\n",
    ")\n",
    "print(f\"Training set: {len(df_train)}, Test set: {len(df_test)}\")\n",
    "\n",
    "# ----------------- 2. KM CENSORING MODEL ON TRAIN SET ONLY -----------------\n",
    "km_c_train = KaplanMeierFitter()\n",
    "km_c_train.fit(\n",
    "    durations=df_train[\"time_to_event\"],\n",
    "    event_observed=1 - df_train[\"event_observed\"]   # 1 = censored\n",
    ")\n",
    "\n",
    "# ----------------- 3. G(t) Diagnostics -----------------\n",
    "print(\"\\n=== CENSORING DISTRIBUTION DIAGNOSTICS ===\")\n",
    "G_values = km_c_train.survival_function_at_times(df_train[\"time_to_event\"]).values\n",
    "print(f\"G(t) range: [{G_values.min():.6f}, {G_values.max():.6f}]\")\n",
    "print(f\"G(t) < 0.01: {(G_values < 0.01).sum()} entries\")\n",
    "print(f\"G(t) < 0.001: {(G_values < 0.001).sum()} entries\")\n",
    "\n",
    "# ----------------- 4. STABILISED IPCW  -----------------\n",
    "G_hat_train = km_c_train.survival_function_at_times(df_train[\"time_to_event\"]).values\n",
    "G_hat_train = np.clip(G_hat_train, 0.01, 1.0)  # ðŸ”¹ Clip at 0.01 (not 0.05)\n",
    "\n",
    "# Raw weights 1/G(t)\n",
    "ipcw_raw = 1 / G_hat_train\n",
    "\n",
    "# Clip max weight for stability\n",
    "MAX_WEIGHT = 15\n",
    "ipcw_train_events = np.clip(ipcw_raw, 0, MAX_WEIGHT)\n",
    "\n",
    "# Stabilised censoring weights\n",
    "ipcw_train = np.where(\n",
    "    df_train[\"event_observed\"] == 1,               # event occurred\n",
    "    ipcw_train_events,\n",
    "    G_hat_train / (1 - G_hat_train + 1e-6)         # censored weight\n",
    ")\n",
    "\n",
    "df_ipcw_train = df_train.assign(ipcw=ipcw_train)\n",
    "\n",
    "# ----------------- 5. STABILISED IPCW -----------------\n",
    "G_hat_test = km_c_train.survival_function_at_times(df_test[\"time_to_event\"]).values\n",
    "G_hat_test = np.clip(G_hat_test, 0.01, 1.0)        # same clipping rule\n",
    "\n",
    "ipcw_raw_test = 1 / G_hat_test\n",
    "ipcw_test_events = np.clip(ipcw_raw_test, 0, MAX_WEIGHT)\n",
    "\n",
    "ipcw_test = np.where(\n",
    "    df_test[\"event_observed\"] == 1,\n",
    "    ipcw_test_events,\n",
    "    G_hat_test / (1 - G_hat_test + 1e-6)\n",
    ")\n",
    "\n",
    "df_ipcw_test = df_test.assign(ipcw=ipcw_test)\n",
    "\n",
    "# ----------------- 6. SAVE DATA -----------------\n",
    "df_ipcw = pd.concat([df_ipcw_train, df_ipcw_test], ignore_index=True)\n",
    "df_ipcw[\"method\"] = \"ipcw\"\n",
    "df_ipcw.to_csv(\"data/censoring_methods/data_ipcw.csv\", index=False)\n",
    "\n",
    "print(\"\\nâœ… Stabilised IPCW saved to data/censoring_methods/data_ipcw.csv\")\n",
    "print(f\"Weight stats â†’ Min={df_ipcw['ipcw'].min():.4f} | Max={df_ipcw['ipcw'].max():.4f} | Mean={df_ipcw['ipcw'].mean():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0339c39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_discard = df.copy()  # Keep all data (both censored and uncensored)\n",
    "df_discard[\"method\"] = \"discard\"\n",
    "\n",
    "# Add discard weights: 1 for events, 0 for censored\n",
    "df_discard[\"discard_weight\"] = df_discard[\"event_observed\"].astype(float)  # 1 for events, 0 for censored\n",
    "\n",
    "df_discard.to_csv(\"data/censoring_methods/data_discard.csv\", index=False)\n",
    "print(\"Saved:\", \"data/censoring_methods/data_discard.csv\")\n",
    "\n",
    "# Check the weights\n",
    "print(f\"Discard weights - Events (1): {(df_discard['discard_weight'] == 1).sum()}\")\n",
    "print(f\"Discard weights - Censored (0): {(df_discard['discard_weight'] == 0).sum()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
