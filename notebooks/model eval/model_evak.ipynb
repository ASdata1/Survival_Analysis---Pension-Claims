{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06b9d0d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Install scikit-survival package\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"scikit-survival\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53641d7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn==1.3.2 in c:\\users\\04ama\\anaconda3\\lib\\site-packages (1.3.2)\n",
      "Requirement already satisfied: scikit-survival==0.22.2 in c:\\users\\04ama\\anaconda3\\lib\\site-packages (0.22.2)\n",
      "Requirement already satisfied: numpy<2.0,>=1.17.3 in c:\\users\\04ama\\anaconda3\\lib\\site-packages (from scikit-learn==1.3.2) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\04ama\\anaconda3\\lib\\site-packages (from scikit-learn==1.3.2) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\04ama\\anaconda3\\lib\\site-packages (from scikit-learn==1.3.2) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\04ama\\anaconda3\\lib\\site-packages (from scikit-learn==1.3.2) (3.5.0)\n",
      "Requirement already satisfied: ecos in c:\\users\\04ama\\anaconda3\\lib\\site-packages (from scikit-survival==0.22.2) (2.0.14)\n",
      "Requirement already satisfied: numexpr in c:\\users\\04ama\\anaconda3\\lib\\site-packages (from scikit-survival==0.22.2) (2.8.7)\n",
      "Requirement already satisfied: osqp!=0.6.0,!=0.6.1 in c:\\users\\04ama\\anaconda3\\lib\\site-packages (from scikit-survival==0.22.2) (0.6.7.post3)\n",
      "Requirement already satisfied: pandas>=1.0.5 in c:\\users\\04ama\\anaconda3\\lib\\site-packages (from scikit-survival==0.22.2) (2.3.1)\n",
      "Requirement already satisfied: qdldl in c:\\users\\04ama\\anaconda3\\lib\\site-packages (from osqp!=0.6.0,!=0.6.1->scikit-survival==0.22.2) (0.1.7.post5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\04ama\\anaconda3\\lib\\site-packages (from pandas>=1.0.5->scikit-survival==0.22.2) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\04ama\\anaconda3\\lib\\site-packages (from pandas>=1.0.5->scikit-survival==0.22.2) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\04ama\\anaconda3\\lib\\site-packages (from pandas>=1.0.5->scikit-survival==0.22.2) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\04ama\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=1.0.5->scikit-survival==0.22.2) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%pip install scikit-learn==1.3.2 scikit-survival==0.22.2\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from lifelines import CoxPHFitter, WeibullAFTFitter\n",
    "from lifelines.utils import concordance_index\n",
    "from sksurv.util import Surv\n",
    "from sksurv.metrics import (\n",
    "    concordance_index_ipcw,\n",
    "    integrated_brier_score,\n",
    "    brier_score,\n",
    "    cumulative_dynamic_auc\n",
    ")\n",
    "\n",
    "\n",
    "# Load datasets\n",
    "df_zero    = pd.read_csv(\"C:\\\\Users\\\\04ama\\\\OneDrive\\\\pension survival analysis\\\\notebooks\\\\ipcw_and_other_censoring\\\\data\\\\censoring_methods\\\\data_zero.csv\")\n",
    "df_discard = pd.read_csv(\"C:\\\\Users\\\\04ama\\\\OneDrive\\\\pension survival analysis\\\\notebooks\\\\ipcw_and_other_censoring\\\\data\\\\censoring_methods\\\\data_discard.csv\")\n",
    "df_ipcw    = pd.read_csv(\"C:\\\\Users\\\\04ama\\\\OneDrive\\\\pension survival analysis\\\\notebooks\\\\ipcw_and_other_censoring\\\\data\\\\censoring_methods\\\\data_ipcw.csv\")\n",
    "\n",
    "datasets = {\"zero\": df_zero, \"discard\": df_discard, \"ipcw\": df_ipcw}\n",
    "\n",
    "X_COLS = [\"age_at_entry\", \"income_level\", \"health_score\", \"pension_contrib_rate\"]\n",
    "DUR = \"time_to_event\"\n",
    "EVT = \"event_observed\"\n",
    "T_STAR = 15.0\n",
    "# Adjust TIMES to be within the valid follow-up range [0.04; 25.0[\n",
    "TIMES = np.array([1.0, 5.0, 10.0, 15.0, 17.0])  # Changed from (5, 30, 6) to (1, 24, 6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a71fee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lifelines import KaplanMeierFitter\n",
    "from sksurv.metrics import concordance_index_ipcw, integrated_brier_score, cumulative_dynamic_auc\n",
    "from sksurv.util import Surv\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score\n",
    "import numpy as np\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# Convert dataframe into sksurv-compatible survival object\n",
    "# ------------------------------------------------------\n",
    "def make_surv(df):\n",
    "    \"\"\"\n",
    "    Convert a pandas DataFrame into a structured survival array.\n",
    "\n",
    "    Parameters:\n",
    "    - df: DataFrame with event column (EVT) and duration column (DUR)\n",
    "\n",
    "    Returns:\n",
    "    - Structured array usable for sksurv models and metrics\n",
    "    \"\"\"\n",
    "    return Surv.from_arrays(event=df[EVT].astype(bool), time=df[DUR])\n",
    "\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# Evaluate survival models using IPCW-based metrics\n",
    "# ------------------------------------------------------\n",
    "def evaluate_survival_model(model_name, model, train_df, test_df):\n",
    "    \"\"\"\n",
    "    Evaluate a fitted survival model using:\n",
    "    - Uno's C-index (concordance_index_ipcw)\n",
    "    - Integrated Brier Score (IBS)\n",
    "    - Time-dependent AUC at a specified evaluation time (T_STAR)\n",
    "\n",
    "    Parameters:\n",
    "    - model_name: string name of the model\n",
    "    - model: a trained survival model with predict_survival_function()\n",
    "    - train_df, test_df: DataFrames containing duration, event, and predictors\n",
    "\n",
    "    Returns:\n",
    "    - Dictionary containing C-index, IBS, and AUC at T_STAR\n",
    "    \"\"\"\n",
    "    y_tr = make_surv(train_df)\n",
    "    y_te = make_surv(test_df)\n",
    "\n",
    "    # Predict full survival function S(t|x) across test samples\n",
    "    S_pred = model.predict_survival_function(test_df[X_COLS], times=TIMES).T.values\n",
    "\n",
    "    # Event risk = 1 - survival probability at the final time point\n",
    "    risk_scores = 1 - S_pred[:, -1]\n",
    "\n",
    "    # IPCW-adjusted C-index (Uno's version)\n",
    "    c_uno = concordance_index_ipcw(y_tr, y_te, -risk_scores, tau=TIMES[-1])[0]\n",
    "\n",
    "    # Integrated Brier Score over TIMES\n",
    "    ibs = integrated_brier_score(y_tr, y_te, S_pred, TIMES)\n",
    "\n",
    "    # Time-dependent AUC\n",
    "    auc_times, aucs = cumulative_dynamic_auc(y_tr, y_te, risk_scores, TIMES)\n",
    "\n",
    "    # Extract AUC at T_STAR (closest time point)\n",
    "    if np.isscalar(aucs):\n",
    "        auc_15 = float(aucs)\n",
    "    else:\n",
    "        closest_idx = np.argmin(np.abs(auc_times - T_STAR))\n",
    "        auc_15 = float(aucs[closest_idx])\n",
    "\n",
    "    return {\"Model\": model_name, \"C_index\": c_uno, \"IBS\": ibs, \"AUC@15\": auc_15}\n",
    "\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# Evaluate classifier + optionally compute NRI vs baseline\n",
    "# ------------------------------------------------------\n",
    "def evaluate_classifier(model_name, model, X_train, y_train, X_test, y_test, \n",
    "                        sample_weight=None, baseline_proba=None, cutoff=0.5):\n",
    "    \"\"\"\n",
    "    Train and evaluate a binary classifier with accuracy, AUC, F1, and optional NRI.\n",
    "\n",
    "    Parameters:\n",
    "    - model_name: str, name of the classifier\n",
    "    - model: sklearn model or pipeline\n",
    "    - X_train, y_train: training data and binary labels\n",
    "    - X_test, y_test: test data and labels\n",
    "    - sample_weight: optional IPCW or class weights\n",
    "    - baseline_proba: predicted probabilities from baseline model (for NRI)\n",
    "    - cutoff: threshold for risk reclassification (default = 0.5)\n",
    "\n",
    "    Returns:\n",
    "    - metrics: dict with Accuracy, AUC, F1, and NRI values\n",
    "    - y_pred_proba: predictions probabilities (used to store baseline for next models)\n",
    "    \"\"\"\n",
    "\n",
    "    # Fit the model (if weights are supported, use them)\n",
    "    if sample_weight is not None and hasattr(model, 'fit') and 'sample_weight' in model.fit.__code__.co_varnames:\n",
    "        model.fit(X_train, y_train, sample_weight=sample_weight)\n",
    "    else:\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "    # Predict labels\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "    # Get probability or score output for AUC/NRI\n",
    "    if hasattr(model, 'predict_proba'):\n",
    "        y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "        auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    elif hasattr(model, 'decision_function'):\n",
    "        scores = model.decision_function(X_test)\n",
    "        auc = roc_auc_score(y_test, scores)\n",
    "        y_pred_proba = 1 / (1 + np.exp(-scores))  # Convert to probabilities\n",
    "    else:\n",
    "        auc = np.nan\n",
    "        y_pred_proba = y_pred.astype(float)\n",
    "\n",
    "    # Default NRI values\n",
    "    nri_events = np.nan\n",
    "    nri_nonevents = np.nan\n",
    "    nri_total = np.nan\n",
    "\n",
    "    # Compute NRI only if baseline probabilities are provided\n",
    "    if baseline_proba is not None:\n",
    "        try:\n",
    "            # Binary classification based on threshold\n",
    "            baseline_class = (baseline_proba >= cutoff).astype(int)\n",
    "            new_class = (y_pred_proba >= cutoff).astype(int)\n",
    "\n",
    "            # NRI for events (y=1)\n",
    "            events = (y_test == 1)\n",
    "            if np.sum(events) > 0:\n",
    "                up = np.sum((new_class[events] == 1) & (baseline_class[events] == 0))\n",
    "                down = np.sum((new_class[events] == 0) & (baseline_class[events] == 1))\n",
    "                nri_events = (up - down) / np.sum(events)\n",
    "\n",
    "            # NRI for non-events (y=0)\n",
    "            nonevents = (y_test == 0)\n",
    "            if np.sum(nonevents) > 0:\n",
    "                up = np.sum((new_class[nonevents] == 0) & (baseline_class[nonevents] == 1))\n",
    "                down = np.sum((new_class[nonevents] == 1) & (baseline_class[nonevents] == 0))\n",
    "                nri_nonevents = (up - down) / np.sum(nonevents)\n",
    "\n",
    "            # Total NRI\n",
    "            nri_total = nri_events + nri_nonevents\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"NRI could not be calculated for {model_name}: {e}\")\n",
    "\n",
    "    # Return metrics and predicted probabilities\n",
    "    return {\n",
    "        \"Model\": model_name,\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"AUC\": auc,\n",
    "        \"F1\": f1,\n",
    "        \"NRI_Events\": nri_events,\n",
    "        \"NRI_Non_Events\": nri_nonevents,\n",
    "        \"NRI_Total\": nri_total\n",
    "    }, y_pred_proba\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ae76b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== METHOD: ZERO ===\n",
      "\n",
      "=== METHOD: DISCARD ===\n",
      "\n",
      "=== METHOD: IPCW ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\04ama\\anaconda3\\Lib\\site-packages\\lifelines\\fitters\\__init__.py:1379: StatisticalWarning: It appears your weights are not integers, possibly propensity or sampling scores then?\n",
      "                                        It's important to know that the naive variance estimates of the coefficients are biased. Instead a) set `robust=True` in the call to `fit`, or b) use Monte Carlo to\n",
      "                                        estimate the variances. See paper \"Variance estimation when using inverse probability of treatment weighting (IPTW) with survival analysis\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Results saved to results.csv\n",
      "\n",
      "=== SURVIVAL MODELS ===\n",
      "         Model   Method  C_index     IBS  AUC@15\n",
      "0        CoxPH     zero   0.4136  0.1683  0.3792\n",
      "1   WeibullAFT     zero   0.4131  0.1677  0.3791\n",
      "6        CoxPH  discard   0.4136  0.1683  0.3792\n",
      "7   WeibullAFT  discard   0.4131  0.1677  0.3791\n",
      "12       CoxPH     ipcw   0.4186  0.7514  0.7000\n",
      "13  WeibullAFT     ipcw   0.4195  0.7457  0.7000\n",
      "\n",
      "=== CLASSIFICATION MODELS ===\n",
      "                  Model   Method  Accuracy     AUC      F1  NRI_Events  \\\n",
      "2   Logistic Regression     zero    0.8027  0.8044  0.4770         NaN   \n",
      "3         Random Forest     zero    0.7820  0.7617  0.4595         NaN   \n",
      "4             SVM (RBF)     zero    0.7987  0.7321  0.4102         NaN   \n",
      "5                   KNN     zero    0.8020  0.7854  0.4835         NaN   \n",
      "8   Logistic Regression  discard    0.8027  0.8044  0.4770      0.0000   \n",
      "9         Random Forest  discard    0.7820  0.7617  0.4595      0.0000   \n",
      "10            SVM (RBF)  discard    0.7987  0.7321  0.4102      0.0000   \n",
      "11                  KNN  discard    0.8020  0.7854  0.4835      0.0000   \n",
      "14  Logistic Regression     ipcw    0.7887  0.7898  0.4349     -0.0353   \n",
      "15        Random Forest     ipcw    0.7800  0.7519  0.4231     -0.0516   \n",
      "16            SVM (RBF)     ipcw    0.7840  0.7169  0.3571     -0.0353   \n",
      "17                  KNN     ipcw    0.7840  0.7690  0.4088     -0.0707   \n",
      "\n",
      "    NRI_Non_Events  NRI_Total  \n",
      "2              NaN        NaN  \n",
      "3              NaN        NaN  \n",
      "4              NaN        NaN  \n",
      "5              NaN        NaN  \n",
      "8           0.0000     0.0000  \n",
      "9           0.0000     0.0000  \n",
      "10          0.0000     0.0000  \n",
      "11          0.0000     0.0000  \n",
      "14         -0.0097    -0.0450  \n",
      "15          0.0106    -0.0410  \n",
      "16         -0.0115    -0.0468  \n",
      "17         -0.0018    -0.0724  \n",
      "\n",
      "=== NRI SUMMARY (vs Zero Method) ===\n",
      "Method               discard    ipcw\n",
      "Model                               \n",
      "KNN                      0.0 -0.0724\n",
      "Logistic Regression      0.0 -0.0450\n",
      "Random Forest            0.0 -0.0410\n",
      "SVM (RBF)                0.0 -0.0468\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>C_index</th>\n",
       "      <th>IBS</th>\n",
       "      <th>AUC@15</th>\n",
       "      <th>Method</th>\n",
       "      <th>Model_Type</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>F1</th>\n",
       "      <th>NRI_Events</th>\n",
       "      <th>NRI_Non_Events</th>\n",
       "      <th>NRI_Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CoxPH</td>\n",
       "      <td>0.413586</td>\n",
       "      <td>0.168297</td>\n",
       "      <td>0.379209</td>\n",
       "      <td>zero</td>\n",
       "      <td>Survival</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WeibullAFT</td>\n",
       "      <td>0.413129</td>\n",
       "      <td>0.167703</td>\n",
       "      <td>0.379082</td>\n",
       "      <td>zero</td>\n",
       "      <td>Survival</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>zero</td>\n",
       "      <td>Classification</td>\n",
       "      <td>0.802667</td>\n",
       "      <td>0.804357</td>\n",
       "      <td>0.477032</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>zero</td>\n",
       "      <td>Classification</td>\n",
       "      <td>0.782000</td>\n",
       "      <td>0.761658</td>\n",
       "      <td>0.459504</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SVM (RBF)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>zero</td>\n",
       "      <td>Classification</td>\n",
       "      <td>0.798667</td>\n",
       "      <td>0.732089</td>\n",
       "      <td>0.410156</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>KNN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>zero</td>\n",
       "      <td>Classification</td>\n",
       "      <td>0.802000</td>\n",
       "      <td>0.785375</td>\n",
       "      <td>0.483478</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CoxPH</td>\n",
       "      <td>0.413586</td>\n",
       "      <td>0.168297</td>\n",
       "      <td>0.379209</td>\n",
       "      <td>discard</td>\n",
       "      <td>Survival</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>WeibullAFT</td>\n",
       "      <td>0.413129</td>\n",
       "      <td>0.167703</td>\n",
       "      <td>0.379082</td>\n",
       "      <td>discard</td>\n",
       "      <td>Survival</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>discard</td>\n",
       "      <td>Classification</td>\n",
       "      <td>0.802667</td>\n",
       "      <td>0.804357</td>\n",
       "      <td>0.477032</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>discard</td>\n",
       "      <td>Classification</td>\n",
       "      <td>0.782000</td>\n",
       "      <td>0.761658</td>\n",
       "      <td>0.459504</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SVM (RBF)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>discard</td>\n",
       "      <td>Classification</td>\n",
       "      <td>0.798667</td>\n",
       "      <td>0.732089</td>\n",
       "      <td>0.410156</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>KNN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>discard</td>\n",
       "      <td>Classification</td>\n",
       "      <td>0.802000</td>\n",
       "      <td>0.785375</td>\n",
       "      <td>0.483478</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>CoxPH</td>\n",
       "      <td>0.418619</td>\n",
       "      <td>0.751402</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>ipcw</td>\n",
       "      <td>Survival</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>WeibullAFT</td>\n",
       "      <td>0.419477</td>\n",
       "      <td>0.745662</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>ipcw</td>\n",
       "      <td>Survival</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ipcw</td>\n",
       "      <td>Classification</td>\n",
       "      <td>0.788667</td>\n",
       "      <td>0.789834</td>\n",
       "      <td>0.434938</td>\n",
       "      <td>-0.035326</td>\n",
       "      <td>-0.009717</td>\n",
       "      <td>-0.045043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ipcw</td>\n",
       "      <td>Classification</td>\n",
       "      <td>0.780000</td>\n",
       "      <td>0.751858</td>\n",
       "      <td>0.423077</td>\n",
       "      <td>-0.051630</td>\n",
       "      <td>0.010601</td>\n",
       "      <td>-0.041030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>SVM (RBF)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ipcw</td>\n",
       "      <td>Classification</td>\n",
       "      <td>0.784000</td>\n",
       "      <td>0.716854</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>-0.035326</td>\n",
       "      <td>-0.011484</td>\n",
       "      <td>-0.046810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>KNN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ipcw</td>\n",
       "      <td>Classification</td>\n",
       "      <td>0.784000</td>\n",
       "      <td>0.768988</td>\n",
       "      <td>0.408759</td>\n",
       "      <td>-0.070652</td>\n",
       "      <td>-0.001767</td>\n",
       "      <td>-0.072419</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Model   C_index       IBS    AUC@15   Method  \\\n",
       "0                 CoxPH  0.413586  0.168297  0.379209     zero   \n",
       "1            WeibullAFT  0.413129  0.167703  0.379082     zero   \n",
       "2   Logistic Regression       NaN       NaN       NaN     zero   \n",
       "3         Random Forest       NaN       NaN       NaN     zero   \n",
       "4             SVM (RBF)       NaN       NaN       NaN     zero   \n",
       "5                   KNN       NaN       NaN       NaN     zero   \n",
       "6                 CoxPH  0.413586  0.168297  0.379209  discard   \n",
       "7            WeibullAFT  0.413129  0.167703  0.379082  discard   \n",
       "8   Logistic Regression       NaN       NaN       NaN  discard   \n",
       "9         Random Forest       NaN       NaN       NaN  discard   \n",
       "10            SVM (RBF)       NaN       NaN       NaN  discard   \n",
       "11                  KNN       NaN       NaN       NaN  discard   \n",
       "12                CoxPH  0.418619  0.751402  0.700000     ipcw   \n",
       "13           WeibullAFT  0.419477  0.745662  0.700000     ipcw   \n",
       "14  Logistic Regression       NaN       NaN       NaN     ipcw   \n",
       "15        Random Forest       NaN       NaN       NaN     ipcw   \n",
       "16            SVM (RBF)       NaN       NaN       NaN     ipcw   \n",
       "17                  KNN       NaN       NaN       NaN     ipcw   \n",
       "\n",
       "        Model_Type  Accuracy       AUC        F1  NRI_Events  NRI_Non_Events  \\\n",
       "0         Survival       NaN       NaN       NaN         NaN             NaN   \n",
       "1         Survival       NaN       NaN       NaN         NaN             NaN   \n",
       "2   Classification  0.802667  0.804357  0.477032         NaN             NaN   \n",
       "3   Classification  0.782000  0.761658  0.459504         NaN             NaN   \n",
       "4   Classification  0.798667  0.732089  0.410156         NaN             NaN   \n",
       "5   Classification  0.802000  0.785375  0.483478         NaN             NaN   \n",
       "6         Survival       NaN       NaN       NaN         NaN             NaN   \n",
       "7         Survival       NaN       NaN       NaN         NaN             NaN   \n",
       "8   Classification  0.802667  0.804357  0.477032    0.000000        0.000000   \n",
       "9   Classification  0.782000  0.761658  0.459504    0.000000        0.000000   \n",
       "10  Classification  0.798667  0.732089  0.410156    0.000000        0.000000   \n",
       "11  Classification  0.802000  0.785375  0.483478    0.000000        0.000000   \n",
       "12        Survival       NaN       NaN       NaN         NaN             NaN   \n",
       "13        Survival       NaN       NaN       NaN         NaN             NaN   \n",
       "14  Classification  0.788667  0.789834  0.434938   -0.035326       -0.009717   \n",
       "15  Classification  0.780000  0.751858  0.423077   -0.051630        0.010601   \n",
       "16  Classification  0.784000  0.716854  0.357143   -0.035326       -0.011484   \n",
       "17  Classification  0.784000  0.768988  0.408759   -0.070652       -0.001767   \n",
       "\n",
       "    NRI_Total  \n",
       "0         NaN  \n",
       "1         NaN  \n",
       "2         NaN  \n",
       "3         NaN  \n",
       "4         NaN  \n",
       "5         NaN  \n",
       "6         NaN  \n",
       "7         NaN  \n",
       "8    0.000000  \n",
       "9    0.000000  \n",
       "10   0.000000  \n",
       "11   0.000000  \n",
       "12        NaN  \n",
       "13        NaN  \n",
       "14  -0.045043  \n",
       "15  -0.041030  \n",
       "16  -0.046810  \n",
       "17  -0.072419  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ----------------- Enhanced classifier evaluation with NRI -----------------\n",
    "def evaluate_classifier_with_nri(model_name, model, X_train, y_train, X_test, y_test, sample_weight=None, baseline_proba=None):\n",
    "    \"\"\"\n",
    "    Evaluate a binary classifier and calculate NRI (Net Reclassification Improvement) if baseline predictions are provided.\n",
    "\n",
    "    Returns:\n",
    "    - dict with Accuracy, AUC, F1, NRI_Events, NRI_Non_Events, NRI_Total\n",
    "    - predicted probabilities (for storing as baseline later when method='zero')\n",
    "    \"\"\"\n",
    "    # Fit model (use IPCW if supported)\n",
    "    if sample_weight is not None and hasattr(model, 'fit') and 'sample_weight' in model.fit.__code__.co_varnames:\n",
    "        model.fit(X_train, y_train, sample_weight=sample_weight)\n",
    "    else:\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "    # Standard predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    # Probability scores (for AUC + NRI)\n",
    "    if hasattr(model, 'predict_proba'):\n",
    "        y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "        auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    elif hasattr(model, 'decision_function'):\n",
    "        scores = model.decision_function(X_test)\n",
    "        auc = roc_auc_score(y_test, scores)\n",
    "        y_pred_proba = 1 / (1 + np.exp(-scores))\n",
    "    else:\n",
    "        auc = np.nan\n",
    "        y_pred_proba = y_pred.astype(float)\n",
    "\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "    # Default NRI values\n",
    "    nri_events = nri_non_events = nri_total = np.nan\n",
    "\n",
    "    # If baseline probabilities exist (from zero method), compute NRI\n",
    "    if baseline_proba is not None:\n",
    "        try:\n",
    "            cutoff = 0.5\n",
    "            baseline_class = (baseline_proba >= cutoff).astype(int)\n",
    "            new_class = (y_pred_proba >= cutoff).astype(int)\n",
    "\n",
    "            # NRI for events\n",
    "            events = (y_test == 1)\n",
    "            if np.sum(events) > 0:\n",
    "                up = np.sum((new_class[events] == 1) & (baseline_class[events] == 0))\n",
    "                down = np.sum((new_class[events] == 0) & (baseline_class[events] == 1))\n",
    "                nri_events = (up - down) / np.sum(events)\n",
    "\n",
    "            # NRI for non-events\n",
    "            nonevents = (y_test == 0)\n",
    "            if np.sum(nonevents) > 0:\n",
    "                up = np.sum((new_class[nonevents] == 0) & (baseline_class[nonevents] == 1))\n",
    "                down = np.sum((new_class[nonevents] == 1) & (baseline_class[nonevents] == 0))\n",
    "                nri_non_events = (up - down) / np.sum(nonevents)\n",
    "\n",
    "            # Total NRI\n",
    "            nri_total = nri_events + nri_non_events\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: NRI failed for {model_name}: {e}\")\n",
    "            nri_events = nri_non_events = nri_total = np.nan\n",
    "\n",
    "    return {\n",
    "        \"Model\": model_name,\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"AUC\": auc,\n",
    "        \"F1\": f1,\n",
    "        \"NRI_Events\": nri_events,\n",
    "        \"NRI_Non_Events\": nri_non_events,\n",
    "        \"NRI_Total\": nri_total\n",
    "    }, y_pred_proba\n",
    "\n",
    "\n",
    "# ----------------- Main Evaluation Loop -----------------\n",
    "all_results = []\n",
    "baseline_probabilities = {}  # Save zero-method probabilities for NRI comparison\n",
    "\n",
    "for method, df in datasets.items():\n",
    "    print(f\"\\n=== METHOD: {method.upper()} ===\")\n",
    "    train_df, test_df = train_test_split(df, test_size=0.3, random_state=42, stratify=df[EVT])\n",
    "\n",
    "    df_fit = train_df[[DUR, EVT] + X_COLS].copy()\n",
    "\n",
    "    if method == \"ipcw\" and \"ipcw\" in train_df.columns:\n",
    "        df_fit[\"ipcw\"] = train_df[\"ipcw\"]\n",
    "        w_col = \"ipcw\"\n",
    "    else:\n",
    "        w_col = None\n",
    "\n",
    "    # CoxPH\n",
    "    cph = CoxPHFitter()\n",
    "    cph.fit(df_fit, duration_col=DUR, event_col=EVT, weights_col=w_col, robust=True)\n",
    "    res_cph = evaluate_survival_model_robust(\"CoxPH\", cph, train_df, test_df)\n",
    "    res_cph[\"Method\"] = method\n",
    "    res_cph[\"Model_Type\"] = \"Survival\"\n",
    "    all_results.append(res_cph)\n",
    "\n",
    "    # Weibull AFT\n",
    "    aft = WeibullAFTFitter()\n",
    "    if w_col:\n",
    "        df_fit_aft = df_fit.copy()\n",
    "        df_fit_aft[w_col] = np.maximum(df_fit_aft[w_col], 1e-6)\n",
    "        aft.fit(df_fit_aft, duration_col=DUR, event_col=EVT, weights_col=w_col)\n",
    "    else:\n",
    "        aft.fit(df_fit, duration_col=DUR, event_col=EVT)\n",
    "    res_aft = evaluate_survival_model_robust(\"WeibullAFT\", aft, train_df, test_df)\n",
    "    res_aft[\"Method\"] = method\n",
    "    res_aft[\"Model_Type\"] = \"Survival\"\n",
    "    all_results.append(res_aft)\n",
    "\n",
    "    # Classification targets (binary by T_STAR)\n",
    "    y_train = ((train_df[DUR] <= T_STAR) & (train_df[EVT] == 1)).astype(int)\n",
    "    y_test = ((test_df[DUR] <= T_STAR) & (test_df[EVT] == 1)).astype(int)\n",
    "    X_train, X_test = train_df[X_COLS], test_df[X_COLS]\n",
    "\n",
    "    sw_train = train_df[\"ipcw\"].copy() if method == \"ipcw\" and \"ipcw\" in train_df.columns else None\n",
    "    if sw_train is not None:\n",
    "        sw_train[y_train == 0] = 1e-6\n",
    "\n",
    "    classifiers = {\n",
    "        \"Logistic Regression\": make_pipeline(StandardScaler(), LogisticRegression(max_iter=1000, random_state=42)),\n",
    "        \"Random Forest\": RandomForestClassifier(n_estimators=400, random_state=42),\n",
    "        \"SVM (RBF)\": make_pipeline(StandardScaler(), SVC(probability=True, random_state=42)),\n",
    "        \"KNN\": make_pipeline(StandardScaler(), KNeighborsClassifier(n_neighbors=25))\n",
    "    }\n",
    "\n",
    "    for name, clf in classifiers.items():\n",
    "        baseline_proba = baseline_probabilities.get(name, None) if method != \"zero\" else None\n",
    "\n",
    "        res_clf, y_pred_proba = evaluate_classifier_with_nri(\n",
    "            name, clf, X_train, y_train, X_test, y_test, sample_weight=sw_train, baseline_proba=baseline_proba\n",
    "        )\n",
    "        res_clf[\"Method\"] = method\n",
    "        res_clf[\"Model_Type\"] = \"Classification\"\n",
    "        all_results.append(res_clf)\n",
    "\n",
    "        if method == \"zero\":  # Save baseline for NRI comparison\n",
    "            baseline_probabilities[name] = y_pred_proba\n",
    "\n",
    "# Save results\n",
    "res = pd.DataFrame(all_results)\n",
    "res.to_csv(\"results.csv\", index=False)\n",
    "display(res)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f3de83a",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
