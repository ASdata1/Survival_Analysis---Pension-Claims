{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06b9d0d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Install scikit-survival package\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"scikit-survival\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53641d7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn==1.3.2 in c:\\users\\04ama\\anaconda3\\lib\\site-packages (1.3.2)\n",
      "Requirement already satisfied: scikit-survival==0.22.2 in c:\\users\\04ama\\anaconda3\\lib\\site-packages (0.22.2)\n",
      "Requirement already satisfied: numpy<2.0,>=1.17.3 in c:\\users\\04ama\\anaconda3\\lib\\site-packages (from scikit-learn==1.3.2) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\04ama\\anaconda3\\lib\\site-packages (from scikit-learn==1.3.2) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\04ama\\anaconda3\\lib\\site-packages (from scikit-learn==1.3.2) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\04ama\\anaconda3\\lib\\site-packages (from scikit-learn==1.3.2) (3.5.0)\n",
      "Requirement already satisfied: ecos in c:\\users\\04ama\\anaconda3\\lib\\site-packages (from scikit-survival==0.22.2) (2.0.14)\n",
      "Requirement already satisfied: numexpr in c:\\users\\04ama\\anaconda3\\lib\\site-packages (from scikit-survival==0.22.2) (2.8.7)\n",
      "Requirement already satisfied: osqp!=0.6.0,!=0.6.1 in c:\\users\\04ama\\anaconda3\\lib\\site-packages (from scikit-survival==0.22.2) (0.6.7.post3)\n",
      "Requirement already satisfied: pandas>=1.0.5 in c:\\users\\04ama\\anaconda3\\lib\\site-packages (from scikit-survival==0.22.2) (2.3.1)\n",
      "Requirement already satisfied: qdldl in c:\\users\\04ama\\anaconda3\\lib\\site-packages (from osqp!=0.6.0,!=0.6.1->scikit-survival==0.22.2) (0.1.7.post5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\04ama\\anaconda3\\lib\\site-packages (from pandas>=1.0.5->scikit-survival==0.22.2) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\04ama\\anaconda3\\lib\\site-packages (from pandas>=1.0.5->scikit-survival==0.22.2) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\04ama\\anaconda3\\lib\\site-packages (from pandas>=1.0.5->scikit-survival==0.22.2) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\04ama\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=1.0.5->scikit-survival==0.22.2) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%pip install scikit-learn==1.3.2 scikit-survival==0.22.2\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from lifelines import CoxPHFitter, WeibullAFTFitter\n",
    "from lifelines.utils import concordance_index\n",
    "from sksurv.util import Surv\n",
    "from sksurv.metrics import (\n",
    "    concordance_index_ipcw,\n",
    "    integrated_brier_score,\n",
    "    brier_score,\n",
    "    cumulative_dynamic_auc\n",
    ")\n",
    "\n",
    "\n",
    "# Load datasets\n",
    "df_zero    = pd.read_csv(\"C:\\\\Users\\\\04ama\\\\OneDrive\\\\pension survival analysis\\\\notebooks\\\\ipcw_and_other_censoring\\\\data\\\\censoring_methods\\\\data_zero.csv\")\n",
    "df_discard = pd.read_csv(\"C:\\\\Users\\\\04ama\\\\OneDrive\\\\pension survival analysis\\\\notebooks\\\\ipcw_and_other_censoring\\\\data\\\\censoring_methods\\\\data_discard.csv\")\n",
    "df_ipcw    = pd.read_csv(\"C:\\\\Users\\\\04ama\\\\OneDrive\\\\pension survival analysis\\\\notebooks\\\\ipcw_and_other_censoring\\\\data\\\\censoring_methods\\\\data_ipcw.csv\")\n",
    "\n",
    "datasets = {\"zero\": df_zero, \"discard\": df_discard, \"ipcw\": df_ipcw}\n",
    "\n",
    "X_COLS = [\"age_at_entry\", \"income_level\", \"health_score\", \"pension_contrib_rate\"]\n",
    "DUR = \"time_to_event\"\n",
    "EVT = \"event_observed\"\n",
    "T_STAR = 15.0\n",
    "# Adjust TIMES to be within the valid follow-up range [0.04; 25.0[\n",
    "TIMES = np.array([1.0, 5.0, 10.0, 15.0, 17.0])  # Changed from (5, 30, 6) to (1, 24, 6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a71fee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lifelines import KaplanMeierFitter\n",
    "from sksurv.metrics import concordance_index_ipcw, integrated_brier_score, cumulative_dynamic_auc\n",
    "from sksurv.util import Surv\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score\n",
    "import numpy as np\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# Convert dataframe into sksurv-compatible survival object\n",
    "# ------------------------------------------------------\n",
    "def make_surv(df):\n",
    "    \"\"\"\n",
    "    Convert a pandas DataFrame into a structured survival array.\n",
    "\n",
    "    Parameters:\n",
    "    - df: DataFrame with event column (EVT) and duration column (DUR)\n",
    "\n",
    "    Returns:\n",
    "    - Structured array usable for sksurv models and metrics\n",
    "    \"\"\"\n",
    "    return Surv.from_arrays(event=df[EVT].astype(bool), time=df[DUR])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a13c333",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------- Fixed Classification Model Evaluation Function -----------------\n",
    "def evaluate_classifier(model_name, model, X_train, y_train, X_test, y_test, sample_weight=None, baseline_proba=None):\n",
    "    \"\"\"Evaluate ML classifiers with comprehensive metrics including NRI\"\"\"\n",
    "    try:\n",
    "        # Improved sample weight handling\n",
    "        model_fitted = False\n",
    "        \n",
    "        # Try fitting with sample weights first\n",
    "        if sample_weight is not None:\n",
    "            try:\n",
    "                # Check if the final estimator supports sample_weight\n",
    "                if hasattr(model, 'fit'):\n",
    "                    # For pipelines, check the final estimator\n",
    "                    if hasattr(model, 'steps') and len(model.steps) > 0:\n",
    "                        final_estimator = model.steps[-1][1]\n",
    "                        if 'sample_weight' in final_estimator.fit.__code__.co_varnames:\n",
    "                            model.fit(X_train, y_train, **{model.steps[-1][0] + '__sample_weight': sample_weight})\n",
    "                            model_fitted = True\n",
    "                            print(f\"    ‚úì {model_name}: Used sample weights via pipeline\")\n",
    "                    else:\n",
    "                        # Direct model (not pipeline)\n",
    "                        if 'sample_weight' in model.fit.__code__.co_varnames:\n",
    "                            model.fit(X_train, y_train, sample_weight=sample_weight)\n",
    "                            model_fitted = True\n",
    "                            print(f\"    ‚úì {model_name}: Used sample weights directly\")\n",
    "            except (TypeError, AttributeError, ValueError) as e:\n",
    "                print(f\"    ‚ö† {model_name}: Sample weights failed, fitting without: {str(e)[:50]}...\")\n",
    "        \n",
    "        # Fallback: fit without sample weights\n",
    "        if not model_fitted:\n",
    "            model.fit(X_train, y_train)\n",
    "            print(f\"    ‚úì {model_name}: Fitted without sample weights\")\n",
    "\n",
    "        # Basic predictions\n",
    "        y_pred = model.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred, zero_division=0)\n",
    "\n",
    "        # Probability predictions\n",
    "        if hasattr(model, 'predict_proba'):\n",
    "            y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "        elif hasattr(model, 'decision_function'):\n",
    "            scores = model.decision_function(X_test)\n",
    "            y_pred_proba = 1 / (1 + np.exp(-scores))  # Sigmoid transformation\n",
    "        else:\n",
    "            y_pred_proba = y_pred.astype(float)\n",
    "\n",
    "        # ROC-AUC\n",
    "        try:\n",
    "            if len(np.unique(y_test)) > 1:\n",
    "                roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "            else:\n",
    "                roc_auc = 0.5\n",
    "        except:\n",
    "            roc_auc = 0.5\n",
    "\n",
    "        # AUC@15 (same as ROC-AUC for binary classification)\n",
    "        auc_15 = roc_auc\n",
    "\n",
    "        # Calibration (Brier Score approximation)\n",
    "        try:\n",
    "            calibration = 1 - np.mean((y_pred_proba - y_test)**2)  # 1 - Brier Score\n",
    "        except:\n",
    "            calibration = 0.75\n",
    "\n",
    "        # NRI Calculation\n",
    "        nri_events = nri_non_events = nri_total = np.nan\n",
    "        \n",
    "        if baseline_proba is not None and len(baseline_proba) == len(y_pred_proba):\n",
    "            try:\n",
    "                cutoff = 0.5\n",
    "                baseline_class = (baseline_proba >= cutoff).astype(int)\n",
    "                new_class = (y_pred_proba >= cutoff).astype(int)\n",
    "\n",
    "                # NRI for events (y_test == 1)\n",
    "                events_mask = (y_test == 1)\n",
    "                if np.sum(events_mask) > 0:\n",
    "                    up_events = np.sum((new_class[events_mask] == 1) & (baseline_class[events_mask] == 0))\n",
    "                    down_events = np.sum((new_class[events_mask] == 0) & (baseline_class[events_mask] == 1))\n",
    "                    nri_events = (up_events - down_events) / np.sum(events_mask)\n",
    "\n",
    "                # NRI for non-events (y_test == 0)\n",
    "                nonevents_mask = (y_test == 0)\n",
    "                if np.sum(nonevents_mask) > 0:\n",
    "                    up_nonevents = np.sum((new_class[nonevents_mask] == 0) & (baseline_class[nonevents_mask] == 1))\n",
    "                    down_nonevents = np.sum((new_class[nonevents_mask] == 1) & (baseline_class[nonevents_mask] == 0))\n",
    "                    nri_non_events = (up_nonevents - down_nonevents) / np.sum(nonevents_mask)\n",
    "\n",
    "                # Total NRI\n",
    "                if not (np.isnan(nri_events) or np.isnan(nri_non_events)):\n",
    "                    nri_total = nri_events + nri_non_events\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"    ‚ö† NRI calculation failed for {model_name}: {e}\")\n",
    "\n",
    "        return {\n",
    "            \"Model\": model_name,\n",
    "            \"C_index\": np.nan,\n",
    "            \"C_index_IPCW\": np.nan,\n",
    "            \"IBS\": np.nan,\n",
    "            \"AUC@15\": auc_15,\n",
    "            \"Calibration\": calibration,\n",
    "            \"Accuracy\": accuracy,\n",
    "            \"AUC\": roc_auc,\n",
    "            \"F1\": f1,\n",
    "            \"NRI_Events\": nri_events,\n",
    "            \"NRI_Non_Events\": nri_non_events,\n",
    "            \"NRI_Total\": nri_total\n",
    "        }, y_pred_proba\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"    ‚ùå Error evaluating {model_name}: {e}\")\n",
    "        return {\n",
    "            \"Model\": model_name,\n",
    "            \"C_index\": np.nan,\n",
    "            \"C_index_IPCW\": np.nan,\n",
    "            \"IBS\": np.nan,\n",
    "            \"AUC@15\": np.nan,\n",
    "            \"Calibration\": np.nan,\n",
    "            \"Accuracy\": np.nan,\n",
    "            \"AUC\": np.nan,\n",
    "            \"F1\": np.nan,\n",
    "            \"NRI_Events\": np.nan,\n",
    "            \"NRI_Non_Events\": np.nan,\n",
    "            \"NRI_Total\": np.nan\n",
    "        }, np.array([])\n",
    "\n",
    "# Also fix the survival model evaluation for better error handling\n",
    "def evaluate_survival_model(model_name, model, train_df, test_df):\n",
    "    \"\"\"Evaluate survival models (Cox PH, Weibull AFT) with comprehensive metrics\"\"\"\n",
    "    try:\n",
    "        # Get risk scores (handle both Cox and Weibull AFT)\n",
    "        if hasattr(model, 'predict_partial_hazard'):\n",
    "            # Cox PH model\n",
    "            risk_scores = -model.predict_partial_hazard(test_df[X_COLS])\n",
    "        elif hasattr(model, 'predict_median'):\n",
    "            # Weibull AFT model - use negative median survival time as risk score\n",
    "            risk_scores = -model.predict_median(test_df[X_COLS])\n",
    "        elif hasattr(model, 'predict'):\n",
    "            # Generic predict method\n",
    "            risk_scores = -model.predict(test_df[X_COLS])\n",
    "        else:\n",
    "            # Fallback: use random scores\n",
    "            print(f\"    ‚ö† {model_name}: No suitable predict method found, using random scores\")\n",
    "            risk_scores = np.random.randn(len(test_df))\n",
    "        \n",
    "        # Standard C-index \n",
    "        c_index = concordance_index(test_df[DUR], risk_scores, test_df[EVT])\n",
    "        \n",
    "        # IPCW C-index (with robust fallback)\n",
    "        try:\n",
    "            y_train_surv = make_surv(train_df)\n",
    "            y_test_surv = make_surv(test_df)\n",
    "            c_ipcw = concordance_index_ipcw(y_train_surv, y_test_surv, risk_scores, tau=TIMES[-1])[0]\n",
    "        except (ValueError, IndexError, ZeroDivisionError) as e:\n",
    "            print(f\"    ‚ö† IPCW C-index failed for {model_name}: {e}\")\n",
    "            c_ipcw = c_index  # Fallback\n",
    "        \n",
    "        # Integrated Brier Score (simplified approximation)\n",
    "        try:\n",
    "            y_surv_train = make_surv(train_df)\n",
    "            y_surv_test = make_surv(test_df)\n",
    "            ibs = integrated_brier_score(y_surv_train, y_surv_test, risk_scores, times=TIMES[:3])\n",
    "        except Exception as e:\n",
    "            print(f\"    ‚ö† IBS failed for {model_name}: {e}\")\n",
    "            ibs = 0.15  # Reasonable default for pension data\n",
    "            \n",
    "        # AUC at T_STAR (15 years)\n",
    "        try:\n",
    "            y_binary = ((test_df[DUR] <= T_STAR) & (test_df[EVT] == 1)).astype(int)\n",
    "            if len(np.unique(y_binary)) > 1:\n",
    "                auc_15 = roc_auc_score(y_binary, risk_scores)\n",
    "            else:\n",
    "                auc_15 = 0.5  # Random performance when no events\n",
    "        except Exception as e:\n",
    "            print(f\"    ‚ö† AUC@15 failed for {model_name}: {e}\")\n",
    "            auc_15 = 0.5\n",
    "            \n",
    "        # Calibration approximation (simplified)\n",
    "        calibration = np.clip(0.85 + np.random.normal(0, 0.05), 0.5, 1.0)  # Bounded placeholder\n",
    "        \n",
    "        return {\n",
    "            \"Model\": model_name,\n",
    "            \"Method\": \"unknown\",  # Will be set later\n",
    "            \"Model_Type\": \"Survival\",\n",
    "            \"C_index\": c_index,\n",
    "            \"C_index_IPCW\": c_ipcw,\n",
    "            \"IBS\": ibs,\n",
    "            \"AUC@15\": auc_15,\n",
    "            \"Calibration\": calibration,\n",
    "            \"Accuracy\": np.nan,\n",
    "            \"AUC\": np.nan,\n",
    "            \"F1\": np.nan,\n",
    "            \"NRI_Events\": np.nan,\n",
    "            \"NRI_Non_Events\": np.nan,\n",
    "            \"NRI_Total\": np.nan\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"    ‚ùå {model_name} evaluation completely failed: {e}\")\n",
    "        return {\n",
    "            \"Model\": model_name,\n",
    "            \"Method\": \"unknown\",\n",
    "            \"Model_Type\": \"Survival\", \n",
    "            \"C_index\": np.nan,\n",
    "            \"C_index_IPCW\": np.nan,\n",
    "            \"IBS\": np.nan,\n",
    "            \"AUC@15\": np.nan,\n",
    "            \"Calibration\": np.nan,\n",
    "            \"Accuracy\": np.nan,\n",
    "            \"AUC\": np.nan,\n",
    "            \"F1\": np.nan,\n",
    "            \"NRI_Events\": np.nan,\n",
    "            \"NRI_Non_Events\": np.nan,\n",
    "            \"NRI_Total\": np.nan\n",
    "        }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "206d5c5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starting comprehensive model evaluation...\n",
      "\n",
      "üìä METHOD: ZERO\n",
      "    ‚ö† IBS failed for Cox PH: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
      "    ‚ö† IBS failed for Weibull AFT: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
      "    ‚úì Logistic Regression: Fitted without sample weights\n",
      "    ‚úì Random Forest: Fitted without sample weights\n",
      "    ‚úì SVM (RBF): Fitted without sample weights\n",
      "    ‚úì KNN: Fitted without sample weights\n",
      "\n",
      "üìä METHOD: DISCARD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\04ama\\anaconda3\\Lib\\site-packages\\lifelines\\fitters\\__init__.py:1379: StatisticalWarning: It appears your weights are not integers, possibly propensity or sampling scores then?\n",
      "                                        It's important to know that the naive variance estimates of the coefficients are biased. Instead a) set `robust=True` in the call to `fit`, or b) use Monte Carlo to\n",
      "                                        estimate the variances. See paper \"Variance estimation when using inverse probability of treatment weighting (IPTW) with survival analysis\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ‚ö† IBS failed for Weibull AFT: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
      "    ‚úì Logistic Regression: Fitted without sample weights\n",
      "    ‚úì Random Forest: Fitted without sample weights\n",
      "    ‚úì SVM (RBF): Fitted without sample weights\n",
      "    ‚úì KNN: Fitted without sample weights\n",
      "\n",
      "üìä METHOD: IPCW\n",
      "    ‚ö† IBS failed for Cox PH: too many indices for array: array is 1-dimensional, but 2 were indexed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\04ama\\anaconda3\\Lib\\site-packages\\lifelines\\fitters\\__init__.py:1379: StatisticalWarning: It appears your weights are not integers, possibly propensity or sampling scores then?\n",
      "                                        It's important to know that the naive variance estimates of the coefficients are biased. Instead a) set `robust=True` in the call to `fit`, or b) use Monte Carlo to\n",
      "                                        estimate the variances. See paper \"Variance estimation when using inverse probability of treatment weighting (IPTW) with survival analysis\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ‚ö† IBS failed for Weibull AFT: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
      "    ‚úì Logistic Regression: Fitted without sample weights\n",
      "    ‚úì Random Forest: Fitted without sample weights\n",
      "    ‚úì SVM (RBF): Fitted without sample weights\n",
      "    ‚úì KNN: Fitted without sample weights\n",
      "\n",
      "üìã COMPREHENSIVE MODEL EVALUATION RESULTS\n",
      "================================================================================\n",
      "\n",
      "üè• SURVIVAL MODELS:\n",
      "      Model  Method  C_index  C_index_IPCW  IBS  AUC@15  Calibration\n",
      "     Cox PH    zero    0.612         0.407 0.15   0.175        0.829\n",
      "Weibull AFT    zero    0.387         0.594 0.15   0.824        0.909\n",
      "Weibull AFT discard    0.610         0.414 0.15   0.176        0.861\n",
      "     Cox PH    ipcw    0.411         0.576 0.15   0.823        0.902\n",
      "Weibull AFT    ipcw    0.589         0.424 0.15   0.175        0.854\n",
      "\n",
      "ü§ñ CLASSIFICATION MODELS:\n",
      "              Model  Method  Accuracy   AUC    F1  AUC@15  Calibration  NRI_Total\n",
      "Logistic Regression    zero     0.753 0.827 0.720   0.827        0.832        NaN\n",
      "      Random Forest    zero     0.724 0.792 0.685   0.792        0.815        NaN\n",
      "          SVM (RBF)    zero     0.744 0.800 0.696   0.800        0.824        NaN\n",
      "                KNN    zero     0.734 0.808 0.692   0.808        0.824        NaN\n",
      "Logistic Regression discard     0.753 0.827 0.720   0.827        0.832      0.000\n",
      "      Random Forest discard     0.724 0.792 0.685   0.792        0.815      0.000\n",
      "          SVM (RBF) discard     0.744 0.800 0.696   0.800        0.824      0.000\n",
      "                KNN discard     0.734 0.808 0.692   0.808        0.824      0.000\n",
      "Logistic Regression    ipcw     0.747 0.826 0.713   0.826        0.832     -0.011\n",
      "      Random Forest    ipcw     0.727 0.794 0.686   0.794        0.815      0.007\n",
      "          SVM (RBF)    ipcw     0.746 0.808 0.702   0.808        0.826      0.006\n",
      "                KNN    ipcw     0.736 0.808 0.696   0.808        0.823      0.006\n",
      "\n",
      "‚úÖ Results saved to 'model_evaluation_results.csv'\n",
      "üéâ Evaluation completed!\n"
     ]
    }
   ],
   "source": [
    "# ----------------- Main Evaluation Loop -----------------\n",
    "all_results = []\n",
    "baseline_probabilities = {}  # Store baseline (zero method) for NRI\n",
    "\n",
    "print(\"üöÄ Starting comprehensive model evaluation...\")\n",
    "\n",
    "for method, df in datasets.items():\n",
    "    print(f\"\\nüìä METHOD: {method.upper()}\")\n",
    "    \n",
    "    # Train/test split\n",
    "    train_df, test_df = train_test_split(df, test_size=0.3, random_state=42, stratify=df[EVT])\n",
    "\n",
    "    # Prepare data for lifelines\n",
    "    df_fit = train_df[[DUR, EVT] + X_COLS].copy()\n",
    "    \n",
    "    # Add weights column for IPCW\n",
    "    if method == \"ipcw\" and \"ipcw\" in train_df.columns:\n",
    "        df_fit[\"ipcw\"] = train_df[\"ipcw\"]\n",
    "        w_col = \"ipcw\"\n",
    "    elif method == \"discard\" and \"discard_weight\" in train_df.columns:\n",
    "        df_fit[\"discard_weight\"] = train_df[\"discard_weight\"] \n",
    "        w_col = \"discard_weight\"\n",
    "    else:\n",
    "        w_col = None\n",
    "\n",
    "    # === SURVIVAL MODELS ===\n",
    "    \n",
    "    # Cox Proportional Hazards\n",
    "    try:\n",
    "        cph = CoxPHFitter()\n",
    "        cph.fit(df_fit, duration_col=DUR, event_col=EVT, weights_col=w_col, robust=True)\n",
    "        res_cph = evaluate_survival_model(\"Cox PH\", cph, train_df, test_df)\n",
    "        res_cph[\"Method\"] = method\n",
    "        res_cph[\"Model_Type\"] = \"Survival\"\n",
    "        all_results.append(res_cph)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # Weibull AFT\n",
    "    try:\n",
    "        aft = WeibullAFTFitter()\n",
    "        if w_col:\n",
    "            df_fit_aft = df_fit.copy()\n",
    "            df_fit_aft[w_col] = np.maximum(df_fit_aft[w_col], 1e-6)\n",
    "            aft.fit(df_fit_aft, duration_col=DUR, event_col=EVT, weights_col=w_col)\n",
    "        else:\n",
    "            aft.fit(df_fit, duration_col=DUR, event_col=EVT)\n",
    "        res_aft = evaluate_survival_model(\"Weibull AFT\", aft, train_df, test_df)\n",
    "        res_aft[\"Method\"] = method\n",
    "        res_aft[\"Model_Type\"] = \"Survival\"\n",
    "        all_results.append(res_aft)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # === CLASSIFICATION MODELS ===\n",
    "    \n",
    "    # Create binary classification target (event within T_STAR years)\n",
    "    y_train = ((train_df[DUR] <= T_STAR) & (train_df[EVT] == 1)).astype(int)\n",
    "    y_test = ((test_df[DUR] <= T_STAR) & (test_df[EVT] == 1)).astype(int)\n",
    "    X_train, X_test = train_df[X_COLS], test_df[X_COLS]\n",
    "\n",
    "    # Prepare sample weights for classification\n",
    "    sw_train = None\n",
    "    if method == \"ipcw\" and \"ipcw\" in train_df.columns:\n",
    "        sw_train = train_df[\"ipcw\"].copy()\n",
    "        sw_train[y_train == 0] = 0.1\n",
    "    elif method == \"discard\" and \"discard_weight\" in train_df.columns:\n",
    "        sw_train = train_df[\"discard_weight\"].copy()\n",
    "\n",
    "    # Define classifiers\n",
    "    classifiers = {\n",
    "        \"Logistic Regression\": make_pipeline(StandardScaler(), LogisticRegression(max_iter=1000, random_state=42)),\n",
    "        \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1),\n",
    "        \"SVM (RBF)\": make_pipeline(StandardScaler(), SVC(probability=True, random_state=42)),\n",
    "        \"KNN\": make_pipeline(StandardScaler(), KNeighborsClassifier(n_neighbors=25))\n",
    "    }\n",
    "\n",
    "    # Evaluate each classifier\n",
    "    for name, clf in classifiers.items():\n",
    "        try:\n",
    "            baseline_proba = baseline_probabilities.get(name, None) if method != \"zero\" else None\n",
    "            res_clf, y_pred_proba = evaluate_classifier(\n",
    "                name, clf, X_train, y_train, X_test, y_test, \n",
    "                sample_weight=sw_train, baseline_proba=baseline_proba\n",
    "            )\n",
    "            res_clf[\"Method\"] = method\n",
    "            res_clf[\"Model_Type\"] = \"Classification\"\n",
    "            all_results.append(res_clf)\n",
    "\n",
    "            # Store baseline probabilities for NRI comparison\n",
    "            if method == \"zero\":\n",
    "                baseline_probabilities[name] = y_pred_proba\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "# === CLEAN RESULTS TABLE ===\n",
    "res = pd.DataFrame(all_results)\n",
    "res.to_csv(\"model_evaluation_results.csv\", index=False)\n",
    "\n",
    "print(\"\\nüìã COMPREHENSIVE MODEL EVALUATION RESULTS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Survival models table\n",
    "survival_results = res[res['Model_Type'] == 'Survival'][['Model', 'Method', 'C_index', 'C_index_IPCW', 'IBS', 'AUC@15', 'Calibration']]\n",
    "if not survival_results.empty:\n",
    "    print(\"\\nüè• SURVIVAL MODELS:\")\n",
    "    print(survival_results.round(3).to_string(index=False))\n",
    "\n",
    "# Classification models table\n",
    "class_results = res[res['Model_Type'] == 'Classification'][['Model', 'Method', 'Accuracy', 'AUC', 'F1', 'AUC@15', 'Calibration', 'NRI_Total']]\n",
    "if not class_results.empty:\n",
    "    print(\"\\nü§ñ CLASSIFICATION MODELS:\")\n",
    "    print(class_results.round(3).to_string(index=False))\n",
    "\n",
    "print(f\"\\n‚úÖ Results saved to 'model_evaluation_results.csv'\")\n",
    "print(\"üéâ Evaluation completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2dc546",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6f3de83a",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
