{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06b9d0d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Install scikit-survival package\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"scikit-survival\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53641d7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn==1.3.2 in c:\\users\\04ama\\anaconda3\\lib\\site-packages (1.3.2)\n",
      "Requirement already satisfied: scikit-survival==0.22.2 in c:\\users\\04ama\\anaconda3\\lib\\site-packages (0.22.2)\n",
      "Requirement already satisfied: numpy<2.0,>=1.17.3 in c:\\users\\04ama\\anaconda3\\lib\\site-packages (from scikit-learn==1.3.2) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\04ama\\anaconda3\\lib\\site-packages (from scikit-learn==1.3.2) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\04ama\\anaconda3\\lib\\site-packages (from scikit-learn==1.3.2) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\04ama\\anaconda3\\lib\\site-packages (from scikit-learn==1.3.2) (3.5.0)\n",
      "Requirement already satisfied: ecos in c:\\users\\04ama\\anaconda3\\lib\\site-packages (from scikit-survival==0.22.2) (2.0.14)\n",
      "Requirement already satisfied: numexpr in c:\\users\\04ama\\anaconda3\\lib\\site-packages (from scikit-survival==0.22.2) (2.8.7)\n",
      "Requirement already satisfied: osqp!=0.6.0,!=0.6.1 in c:\\users\\04ama\\anaconda3\\lib\\site-packages (from scikit-survival==0.22.2) (0.6.7.post3)\n",
      "Requirement already satisfied: pandas>=1.0.5 in c:\\users\\04ama\\anaconda3\\lib\\site-packages (from scikit-survival==0.22.2) (2.3.1)\n",
      "Requirement already satisfied: qdldl in c:\\users\\04ama\\anaconda3\\lib\\site-packages (from osqp!=0.6.0,!=0.6.1->scikit-survival==0.22.2) (0.1.7.post5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\04ama\\anaconda3\\lib\\site-packages (from pandas>=1.0.5->scikit-survival==0.22.2) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\04ama\\anaconda3\\lib\\site-packages (from pandas>=1.0.5->scikit-survival==0.22.2) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\04ama\\anaconda3\\lib\\site-packages (from pandas>=1.0.5->scikit-survival==0.22.2) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\04ama\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=1.0.5->scikit-survival==0.22.2) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "%pip install scikit-learn==1.3.2 scikit-survival==0.22.2\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from lifelines import CoxPHFitter, WeibullAFTFitter\n",
    "from lifelines.utils import concordance_index\n",
    "from sksurv.util import Surv\n",
    "from sksurv.metrics import (\n",
    "    concordance_index_ipcw,\n",
    "    integrated_brier_score,\n",
    "    brier_score,\n",
    "    cumulative_dynamic_auc\n",
    ")\n",
    "\n",
    "# Load datasets\n",
    "df_zero    = pd.read_csv(\"C:\\\\Users\\\\04ama\\\\OneDrive\\\\pension survival analysis\\\\notebooks\\\\ipcw_and_other_censoring\\\\data\\\\censoring_methods\\\\data_zero.csv\")\n",
    "df_discard = pd.read_csv(\"C:\\\\Users\\\\04ama\\\\OneDrive\\\\pension survival analysis\\\\notebooks\\\\ipcw_and_other_censoring\\\\data\\\\censoring_methods\\\\data_discard.csv\")\n",
    "df_ipcw    = pd.read_csv(\"C:\\\\Users\\\\04ama\\\\OneDrive\\\\pension survival analysis\\\\notebooks\\\\ipcw_and_other_censoring\\\\data\\\\censoring_methods\\\\data_ipcw.csv\")\n",
    "\n",
    "datasets = {\"zero\": df_zero, \"discard\": df_discard, \"ipcw\": df_ipcw}\n",
    "\n",
    "X_COLS = [\"age_at_entry\", \"income_level\", \"health_score\", \"pension_contrib_rate\"]\n",
    "DUR = \"time_to_event\"\n",
    "EVT = \"event_observed\"\n",
    "T_STAR = 15.0\n",
    "# Adjust TIMES to be within the valid follow-up range [0.04; 25.0[\n",
    "TIMES = np.linspace(1, 24, 6)  # Changed from (5, 30, 6) to (1, 24, 6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a71fee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lifelines import KaplanMeierFitter\n",
    "from sksurv.metrics import concordance_index_ipcw, integrated_brier_score, cumulative_dynamic_auc\n",
    "\n",
    "def make_surv(df):\n",
    "    return Surv.from_arrays(event=df[EVT].astype(bool), time=df[DUR])\n",
    "\n",
    "def evaluate_survival_model(model_name, model, train_df, test_df, weights=None):\n",
    "    y_tr = make_surv(train_df)\n",
    "    y_te = make_surv(test_df)\n",
    "    S_pred = model.predict_survival_function(test_df[X_COLS], times=TIMES).T.values\n",
    "    risk_scores = 1 - S_pred[:, -1]  # event risk at last time\n",
    "    c_uno = concordance_index_ipcw(y_tr, y_te, -risk_scores, tau=TIMES[-1])[0]\n",
    "    ibs = integrated_brier_score(y_tr, y_te, S_pred, TIMES)\n",
    "    auc_times, aucs = cumulative_dynamic_auc(y_tr, y_te, risk_scores, TIMES)\n",
    "    \n",
    "    # Handle case where aucs might be scalar or array\n",
    "    if np.isscalar(aucs):\n",
    "        auc_15 = float(aucs)\n",
    "    else:\n",
    "        # Find closest time to T_STAR\n",
    "        closest_idx = np.argmin(np.abs(auc_times - T_STAR))\n",
    "        auc_15 = float(aucs[closest_idx])\n",
    "    \n",
    "    return {\"Model\": model_name, \"C_index\": c_uno, \"IBS\": ibs, \"AUC@15\": auc_15}\n",
    "\n",
    "def evaluate_classifier(model_name, model, X_train, y_train, X_test, y_test, sample_weight=None):\n",
    "    \"\"\"Evaluate binary classifier\"\"\"\n",
    "    # Fit model\n",
    "    if sample_weight is not None and hasattr(model, 'fit') and 'sample_weight' in model.fit.__code__.co_varnames:\n",
    "        model.fit(X_train, y_train, sample_weight=sample_weight)\n",
    "    else:\n",
    "        model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    if hasattr(model, 'predict_proba'):\n",
    "        y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "        auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    elif hasattr(model, 'decision_function'):\n",
    "        y_pred_scores = model.decision_function(X_test)\n",
    "        auc = roc_auc_score(y_test, y_pred_scores)\n",
    "    else:\n",
    "        auc = np.nan\n",
    "    \n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    \n",
    "    return {\"Model\": model_name, \"Accuracy\": accuracy, \"AUC\": auc, \"F1\": f1}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "21ae76b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== METHOD: ZERO ===\n",
      "\n",
      "=== METHOD: DISCARD ===\n",
      "\n",
      "=== METHOD: DISCARD ===\n",
      "\n",
      "=== METHOD: IPCW ===\n",
      "\n",
      "=== METHOD: IPCW ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\04ama\\anaconda3\\Lib\\site-packages\\lifelines\\fitters\\coxph_fitter.py:1356: StatisticalWarning: It appears your weights are not integers, possibly propensity or sampling scores then?\n",
      "It's important to know that the naive variance estimates of the coefficients are biased. Instead a) set `robust=True` in the call to `fit`, or b) use Monte Carlo to\n",
      "estimate the variances. See paper \"Variance estimation when using inverse probability of treatment weighting (IPTW) with survival analysis\"\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Enhanced results saved to results.csv\n",
      "\n",
      "=== SURVIVAL MODELS ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Method</th>\n",
       "      <th>C_index</th>\n",
       "      <th>IBS</th>\n",
       "      <th>AUC@15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CoxPH</td>\n",
       "      <td>zero</td>\n",
       "      <td>0.374913</td>\n",
       "      <td>0.160489</td>\n",
       "      <td>0.677311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WeibullAFT</td>\n",
       "      <td>zero</td>\n",
       "      <td>0.374924</td>\n",
       "      <td>0.160390</td>\n",
       "      <td>0.677343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CoxPH</td>\n",
       "      <td>discard</td>\n",
       "      <td>0.374913</td>\n",
       "      <td>0.160489</td>\n",
       "      <td>0.677311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>WeibullAFT</td>\n",
       "      <td>discard</td>\n",
       "      <td>0.374924</td>\n",
       "      <td>0.160390</td>\n",
       "      <td>0.677343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>CoxPH</td>\n",
       "      <td>ipcw</td>\n",
       "      <td>0.383278</td>\n",
       "      <td>0.166091</td>\n",
       "      <td>0.665055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>WeibullAFT</td>\n",
       "      <td>ipcw</td>\n",
       "      <td>0.383411</td>\n",
       "      <td>0.165075</td>\n",
       "      <td>0.664902</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Model   Method   C_index       IBS    AUC@15\n",
       "0        CoxPH     zero  0.374913  0.160489  0.677311\n",
       "1   WeibullAFT     zero  0.374924  0.160390  0.677343\n",
       "6        CoxPH  discard  0.374913  0.160489  0.677311\n",
       "7   WeibullAFT  discard  0.374924  0.160390  0.677343\n",
       "12       CoxPH     ipcw  0.383278  0.166091  0.665055\n",
       "13  WeibullAFT     ipcw  0.383411  0.165075  0.664902"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== CLASSIFICATION MODELS ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Method</th>\n",
       "      <th>C_index</th>\n",
       "      <th>IBS</th>\n",
       "      <th>AUC@15</th>\n",
       "      <th>NRI_total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>zero</td>\n",
       "      <td>0.642143</td>\n",
       "      <td>0.223505</td>\n",
       "      <td>0.642143</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>zero</td>\n",
       "      <td>0.581362</td>\n",
       "      <td>0.242569</td>\n",
       "      <td>0.581362</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SVM (RBF)</td>\n",
       "      <td>zero</td>\n",
       "      <td>0.622832</td>\n",
       "      <td>0.229075</td>\n",
       "      <td>0.622832</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>KNN</td>\n",
       "      <td>zero</td>\n",
       "      <td>0.588189</td>\n",
       "      <td>0.234747</td>\n",
       "      <td>0.588189</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>discard</td>\n",
       "      <td>0.642143</td>\n",
       "      <td>0.223505</td>\n",
       "      <td>0.642143</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>discard</td>\n",
       "      <td>0.581362</td>\n",
       "      <td>0.242569</td>\n",
       "      <td>0.581362</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SVM (RBF)</td>\n",
       "      <td>discard</td>\n",
       "      <td>0.622832</td>\n",
       "      <td>0.229075</td>\n",
       "      <td>0.622832</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>KNN</td>\n",
       "      <td>discard</td>\n",
       "      <td>0.588189</td>\n",
       "      <td>0.234747</td>\n",
       "      <td>0.588189</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>ipcw</td>\n",
       "      <td>0.620438</td>\n",
       "      <td>0.228457</td>\n",
       "      <td>0.620438</td>\n",
       "      <td>0.071540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>ipcw</td>\n",
       "      <td>0.553188</td>\n",
       "      <td>0.252480</td>\n",
       "      <td>0.553188</td>\n",
       "      <td>0.023841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>SVM (RBF)</td>\n",
       "      <td>ipcw</td>\n",
       "      <td>0.572870</td>\n",
       "      <td>0.234276</td>\n",
       "      <td>0.572870</td>\n",
       "      <td>0.050568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>KNN</td>\n",
       "      <td>ipcw</td>\n",
       "      <td>0.569829</td>\n",
       "      <td>0.242064</td>\n",
       "      <td>0.569829</td>\n",
       "      <td>0.012945</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Model   Method   C_index       IBS    AUC@15  NRI_total\n",
       "2   Logistic Regression     zero  0.642143  0.223505  0.642143        NaN\n",
       "3         Random Forest     zero  0.581362  0.242569  0.581362        NaN\n",
       "4             SVM (RBF)     zero  0.622832  0.229075  0.622832        NaN\n",
       "5                   KNN     zero  0.588189  0.234747  0.588189        NaN\n",
       "8   Logistic Regression  discard  0.642143  0.223505  0.642143   0.000000\n",
       "9         Random Forest  discard  0.581362  0.242569  0.581362   0.000000\n",
       "10            SVM (RBF)  discard  0.622832  0.229075  0.622832   0.000000\n",
       "11                  KNN  discard  0.588189  0.234747  0.588189   0.000000\n",
       "14  Logistic Regression     ipcw  0.620438  0.228457  0.620438   0.071540\n",
       "15        Random Forest     ipcw  0.553188  0.252480  0.553188   0.023841\n",
       "16            SVM (RBF)     ipcw  0.572870  0.234276  0.572870   0.050568\n",
       "17                  KNN     ipcw  0.569829  0.242064  0.569829   0.012945"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Add missing import for brier_score_loss\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, brier_score_loss\n",
    "\n",
    "all_results = []\n",
    "baseline_results = {}  # Store baseline predictions for NRI\n",
    "\n",
    "for method, df in datasets.items():\n",
    "    print(f\"\\n=== METHOD: {method.upper()} ===\")\n",
    "    train_df, test_df = train_test_split(df, test_size=0.3, random_state=42, stratify=df[EVT])\n",
    "\n",
    "    df_fit = train_df[[DUR, EVT] + X_COLS].copy()\n",
    "    \n",
    "    # ------------- SURVIVAL MODELS -------------\n",
    "    if method == \"ipcw\" and \"ipcw\" in train_df.columns:\n",
    "        df_fit[\"ipcw\"] = train_df[\"ipcw\"]\n",
    "        w_col = \"ipcw\"\n",
    "    else:\n",
    "        w_col = None\n",
    "\n",
    "    # Cox PH\n",
    "    cph = CoxPHFitter()\n",
    "    cph.fit(df_fit, duration_col=DUR, event_col=EVT,\n",
    "            weights_col=w_col if w_col else None)\n",
    "    \n",
    "    # Survival model evaluation\n",
    "    y_tr = make_surv(train_df)\n",
    "    y_te = make_surv(test_df)\n",
    "    S_pred = cph.predict_survival_function(test_df[X_COLS], times=TIMES).T.values\n",
    "    risk_scores = 1 - S_pred[:, -1]\n",
    "    c_uno = concordance_index_ipcw(y_tr, y_te, -risk_scores, tau=TIMES[-1])[0]\n",
    "    ibs = integrated_brier_score(y_tr, y_te, S_pred, TIMES)\n",
    "    auc_times, aucs = cumulative_dynamic_auc(y_tr, y_te, risk_scores, TIMES)\n",
    "    \n",
    "    if np.isscalar(aucs):\n",
    "        auc_15 = float(aucs)\n",
    "    else:\n",
    "        closest_idx = np.argmin(np.abs(auc_times - T_STAR))\n",
    "        auc_15 = float(aucs[closest_idx])\n",
    "    \n",
    "    res_cph = {\"Model\": \"CoxPH\", \"Method\": method, \"C_index\": c_uno, \"IBS\": ibs, \"AUC@15\": auc_15, \"Model_Type\": \"Survival\"}\n",
    "    all_results.append(res_cph)\n",
    "\n",
    "    # Weibull AFT\n",
    "    aft = WeibullAFTFitter()\n",
    "    aft.fit(df_fit[[DUR, EVT] + X_COLS], duration_col=DUR, event_col=EVT)\n",
    "    \n",
    "    # Weibull evaluation\n",
    "    S_pred_aft = aft.predict_survival_function(test_df[X_COLS], times=TIMES).T.values\n",
    "    risk_scores_aft = 1 - S_pred_aft[:, -1]\n",
    "    c_uno_aft = concordance_index_ipcw(y_tr, y_te, -risk_scores_aft, tau=TIMES[-1])[0]\n",
    "    ibs_aft = integrated_brier_score(y_tr, y_te, S_pred_aft, TIMES)\n",
    "    auc_times_aft, aucs_aft = cumulative_dynamic_auc(y_tr, y_te, risk_scores_aft, TIMES)\n",
    "    \n",
    "    if np.isscalar(aucs_aft):\n",
    "        auc_15_aft = float(aucs_aft)\n",
    "    else:\n",
    "        closest_idx_aft = np.argmin(np.abs(auc_times_aft - T_STAR))\n",
    "        auc_15_aft = float(aucs_aft[closest_idx_aft])\n",
    "    \n",
    "    res_aft = {\"Model\": \"WeibullAFT\", \"Method\": method, \"C_index\": c_uno_aft, \"IBS\": ibs_aft, \"AUC@15\": auc_15_aft, \"Model_Type\": \"Survival\"}\n",
    "    all_results.append(res_aft)\n",
    "\n",
    "    # ------------- CLASSIFIERS -------------\n",
    "    # Convert to binary outcome: event occurred by t*?\n",
    "    y_train = ((train_df[DUR] <= T_STAR) & (train_df[EVT] == 1)).astype(int)\n",
    "    y_test  = ((test_df[DUR] <= T_STAR) & (test_df[EVT] == 1)).astype(int)\n",
    "    X_train, X_test = train_df[X_COLS], test_df[X_COLS]\n",
    "\n",
    "    sw_train = None\n",
    "    if method == \"ipcw\" and \"ipcw\" in train_df.columns:\n",
    "        sw_train = train_df[\"ipcw\"].copy()\n",
    "        sw_train[y_train == 0] = 0  # only count events\n",
    "\n",
    "    classifiers = {\n",
    "        \"Logistic Regression\": make_pipeline(StandardScaler(), LogisticRegression(max_iter=1000)),\n",
    "        \"Random Forest\": RandomForestClassifier(n_estimators=400, random_state=42),\n",
    "        \"SVM (RBF)\": make_pipeline(StandardScaler(), SVC(probability=True, random_state=42)),\n",
    "        \"KNN\": make_pipeline(StandardScaler(), KNeighborsClassifier(n_neighbors=25))\n",
    "    }\n",
    "\n",
    "    for name, clf in classifiers.items():\n",
    "        # Fit classifier\n",
    "        if sw_train is not None and hasattr(clf, 'fit') and 'sample_weight' in clf.fit.__code__.co_varnames:\n",
    "            clf.fit(X_train, y_train, sample_weight=sw_train)\n",
    "        else:\n",
    "            clf.fit(X_train, y_train)\n",
    "        \n",
    "        # Predictions\n",
    "        y_pred = clf.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "        \n",
    "        # Get probabilities\n",
    "        if hasattr(clf, 'predict_proba'):\n",
    "            y_pred_proba = clf.predict_proba(X_test)[:, 1]\n",
    "        elif hasattr(clf, 'decision_function'):\n",
    "            scores = clf.decision_function(X_test)\n",
    "            y_pred_proba = 1 / (1 + np.exp(-scores))  # sigmoid\n",
    "        else:\n",
    "            y_pred_proba = y_pred.astype(float)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        brier = brier_score_loss(y_test, y_pred_proba)\n",
    "        c_index = auc  # C-index same as AUC for binary classification\n",
    "        ibs_clf = brier  # IBS-like metric for classification\n",
    "        \n",
    "        # Calculate NRI (Net Reclassification Improvement)\n",
    "        nri_total = np.nan\n",
    "        if method != \"zero\" and f\"{name}_zero_proba\" in baseline_results:\n",
    "            baseline_proba = baseline_results[f\"{name}_zero_proba\"]\n",
    "            cutoff = 0.5\n",
    "            \n",
    "            # Old and new predictions\n",
    "            y_pred_old = (baseline_proba >= cutoff).astype(int)\n",
    "            y_pred_new = (y_pred_proba >= cutoff).astype(int)\n",
    "            \n",
    "            # NRI for events\n",
    "            events_mask = y_test == 1\n",
    "            if np.sum(events_mask) > 0:\n",
    "                events_improved = np.sum((y_pred_new[events_mask] == 1) & (y_pred_old[events_mask] == 0))\n",
    "                events_worsened = np.sum((y_pred_new[events_mask] == 0) & (y_pred_old[events_mask] == 1))\n",
    "                nri_events = (events_improved - events_worsened) / np.sum(events_mask)\n",
    "            else:\n",
    "                nri_events = 0\n",
    "            \n",
    "            # NRI for non-events\n",
    "            non_events_mask = y_test == 0\n",
    "            if np.sum(non_events_mask) > 0:\n",
    "                non_events_improved = np.sum((y_pred_new[non_events_mask] == 0) & (y_pred_old[non_events_mask] == 1))\n",
    "                non_events_worsened = np.sum((y_pred_new[non_events_mask] == 1) & (y_pred_old[non_events_mask] == 0))\n",
    "                nri_non_events = (non_events_improved - non_events_worsened) / np.sum(non_events_mask)\n",
    "            else:\n",
    "                nri_non_events = 0\n",
    "            \n",
    "            nri_total = nri_events + nri_non_events\n",
    "        \n",
    "        res_clf = {\n",
    "            \"Model\": name, \n",
    "            \"Method\": method, \n",
    "            \"Accuracy\": accuracy, \n",
    "            \"AUC\": auc,\n",
    "            \"AUC@15\": auc,\n",
    "            \"F1\": f1,\n",
    "            \"C_index\": c_index,\n",
    "            \"IBS\": ibs_clf,\n",
    "            \"Brier_Score\": brier,\n",
    "            \"NRI_total\": nri_total,\n",
    "            \"Model_Type\": \"Classification\"\n",
    "        }\n",
    "        all_results.append(res_clf)\n",
    "        \n",
    "        # Store baseline probabilities for NRI calculation\n",
    "        if method == \"zero\":\n",
    "            baseline_results[f\"{name}_zero_proba\"] = y_pred_proba\n",
    "\n",
    "res = pd.DataFrame(all_results)\n",
    "res.to_csv(\"results.csv\", index=False)\n",
    "print(\"\\n✅ Enhanced results saved to results.csv\")\n",
    "\n",
    "# Display results by model type\n",
    "print(\"\\n=== SURVIVAL MODELS ===\")\n",
    "survival_res = res[res['Model_Type'] == 'Survival'][['Model', 'Method', 'C_index', 'IBS', 'AUC@15']]\n",
    "display(survival_res)\n",
    "\n",
    "print(\"\\n=== CLASSIFICATION MODELS ===\")\n",
    "classification_res = res[res['Model_Type'] == 'Classification'][['Model', 'Method', 'C_index', 'IBS', 'AUC@15', 'NRI_total']]\n",
    "display(classification_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f3de83a",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
