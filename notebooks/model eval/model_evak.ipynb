{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b9d0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install scikit-survival package\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"scikit-survival\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53641d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%pip install scikit-learn==1.3.2 scikit-survival==0.22.2\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from lifelines import CoxPHFitter, WeibullAFTFitter\n",
    "from lifelines.utils import concordance_index\n",
    "from sksurv.util import Surv\n",
    "from sksurv.metrics import (\n",
    "    concordance_index_ipcw,\n",
    "    integrated_brier_score,\n",
    "    brier_score,\n",
    "    cumulative_dynamic_auc\n",
    ")\n",
    "\n",
    "\n",
    "# Load datasets\n",
    "df_zero    = pd.read_csv(\"C:\\\\Users\\\\04ama\\\\OneDrive\\\\pension survival analysis\\\\notebooks\\\\ipcw_and_other_censoring\\\\data\\\\censoring_methods\\\\data_zero.csv\")\n",
    "df_discard = pd.read_csv(\"C:\\\\Users\\\\04ama\\\\OneDrive\\\\pension survival analysis\\\\notebooks\\\\ipcw_and_other_censoring\\\\data\\\\censoring_methods\\\\data_discard.csv\")\n",
    "df_ipcw    = pd.read_csv(\"C:\\\\Users\\\\04ama\\\\OneDrive\\\\pension survival analysis\\\\notebooks\\\\ipcw_and_other_censoring\\\\data\\\\censoring_methods\\\\data_ipcw.csv\")\n",
    "\n",
    "datasets = {\"zero\": df_zero, \"discard\": df_discard, \"ipcw\": df_ipcw}\n",
    "\n",
    "X_COLS = [\"age_at_entry\", \"income_level\", \"health_score\", \"pension_contrib_rate\"]\n",
    "DUR = \"time_to_event\"\n",
    "EVT = \"event_observed\"\n",
    "T_STAR = 15.0\n",
    "# Adjust TIMES to be within the valid follow-up range [0.04; 25.0[\n",
    "TIMES = np.array([1.0, 5.0, 10.0, 15.0, 17.0])  # Changed from (5, 30, 6) to (1, 24, 6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a71fee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lifelines import KaplanMeierFitter\n",
    "from sksurv.metrics import concordance_index_ipcw, integrated_brier_score, cumulative_dynamic_auc\n",
    "from sksurv.util import Surv\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score\n",
    "import numpy as np\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# Convert dataframe into sksurv-compatible survival object\n",
    "# ------------------------------------------------------\n",
    "def make_surv(df):\n",
    "    \"\"\"\n",
    "    Convert a pandas DataFrame into a structured survival array.\n",
    "\n",
    "    Parameters:\n",
    "    - df: DataFrame with event column (EVT) and duration column (DUR)\n",
    "\n",
    "    Returns:\n",
    "    - Structured array usable for sksurv models and metrics\n",
    "    \"\"\"\n",
    "    return Surv.from_arrays(event=df[EVT].astype(bool), time=df[DUR])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a13c333",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------- Classification Model Evaluation Function -----------------\n",
    "def evaluate_classifier(model_name, model, X_train, y_train, X_test, y_test, sample_weight=None, baseline_proba=None):\n",
    "    \"\"\"\n",
    "    Evaluate a classification model using various performance metrics including:\n",
    "    - Accuracy, F1 score\n",
    "    - AUC-ROC, AUC@15 (same as AUC in binary classification)\n",
    "    - Calibration score (1 - Brier Score)\n",
    "    - Net Reclassification Improvement (NRI), if baseline probabilities are provided\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model_name : str\n",
    "        Name of the classification model (for reporting purposes).\n",
    "    model : sklearn estimator or pipeline\n",
    "        The machine learning model to evaluate.\n",
    "    X_train, y_train : array-like\n",
    "        Training features and labels.\n",
    "    X_test, y_test : array-like\n",
    "        Test features and labels.\n",
    "    sample_weight : array-like, optional\n",
    "        Case weights for handling censoring (e.g., IPCW). Only used if supported by model.\n",
    "    baseline_proba : array-like, optional\n",
    "        Predicted probabilities from a baseline model for computing NRI.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    results : dict\n",
    "        Dictionary containing evaluation metrics.\n",
    "    y_pred_proba : np.ndarray\n",
    "        Predicted probabilities for the positive class.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        model_fitted = False\n",
    "\n",
    "        # Attempt to fit the model using sample weights (if provided and supported)\n",
    "        if sample_weight is not None:\n",
    "            try:\n",
    "                # If model is a pipeline, check the final estimator\n",
    "                if hasattr(model, 'steps') and len(model.steps) > 0:\n",
    "                    final_estimator = model.steps[-1][1]\n",
    "                    if 'sample_weight' in final_estimator.fit.__code__.co_varnames:\n",
    "                        # Must pass weights using pipeline syntax: <stepname>__sample_weight\n",
    "                        model.fit(X_train, y_train, **{model.steps[-1][0] + '__sample_weight': sample_weight})\n",
    "                        model_fitted = True\n",
    "                else:\n",
    "                    # Non-pipeline model with direct sample_weight support\n",
    "                    if 'sample_weight' in model.fit.__code__.co_varnames:\n",
    "                        model.fit(X_train, y_train, sample_weight=sample_weight)\n",
    "                        model_fitted = True\n",
    "            except (TypeError, AttributeError, ValueError):\n",
    "                # If sample-weight-based fitting fails, fall back to normal fitting\n",
    "                pass\n",
    "\n",
    "        # If model was not fitted using weights, fit normally\n",
    "        if not model_fitted:\n",
    "            model.fit(X_train, y_train)\n",
    "\n",
    "        # Generate predictions\n",
    "        y_pred = model.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred, zero_division=0)\n",
    "\n",
    "        # Predicted probabilities for positive class\n",
    "        if hasattr(model, 'predict_proba'):\n",
    "            y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "        elif hasattr(model, 'decision_function'):\n",
    "            # Convert decision_function to probabilities via logistic transform\n",
    "            scores = model.decision_function(X_test)\n",
    "            y_pred_proba = 1 / (1 + np.exp(-scores))\n",
    "        else:\n",
    "            y_pred_proba = y_pred.astype(float)\n",
    "\n",
    "        # ROC-AUC computation\n",
    "        try:\n",
    "            if len(np.unique(y_test)) > 1:\n",
    "                roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "            else:\n",
    "                roc_auc = 0.5\n",
    "        except:\n",
    "            roc_auc = 0.5\n",
    "\n",
    "        auc_15 = roc_auc  # Same interpretation for binary classification\n",
    "\n",
    "        # Calibration approximation = 1 - Brier score\n",
    "        try:\n",
    "            calibration = 1 - np.mean((y_pred_proba - y_test) ** 2)\n",
    "        except:\n",
    "            calibration = np.nan\n",
    "\n",
    "        # -------------- NRI Computation --------------\n",
    "        nri_events = nri_non_events = nri_total = np.nan\n",
    "\n",
    "        if baseline_proba is not None and len(baseline_proba) == len(y_pred_proba):\n",
    "            try:\n",
    "                cutoff = 0.5\n",
    "                baseline_class = (baseline_proba >= cutoff).astype(int)\n",
    "                new_class = (y_pred_proba >= cutoff).astype(int)\n",
    "\n",
    "                # Event cases (y=1)\n",
    "                events_mask = (y_test == 1)\n",
    "                if np.sum(events_mask) > 0:\n",
    "                    up_events = np.sum((new_class[events_mask] == 1) & (baseline_class[events_mask] == 0))\n",
    "                    down_events = np.sum((new_class[events_mask] == 0) & (baseline_class[events_mask] == 1))\n",
    "                    nri_events = (up_events - down_events) / np.sum(events_mask)\n",
    "\n",
    "                # Non-event cases (y=0)\n",
    "                nonevents_mask = (y_test == 0)\n",
    "                if np.sum(nonevents_mask) > 0:\n",
    "                    up_nonevents = np.sum((new_class[nonevents_mask] == 0) & (baseline_class[nonevents_mask] == 1))\n",
    "                    down_nonevents = np.sum((new_class[nonevents_mask] == 1) & (baseline_class[nonevents_mask] == 0))\n",
    "                    nri_non_events = (up_nonevents - down_nonevents) / np.sum(nonevents_mask)\n",
    "\n",
    "                # Total NRI = sum of event and non-event improvement\n",
    "                if not (np.isnan(nri_events) or np.isnan(nri_non_events)):\n",
    "                    nri_total = nri_events + nri_non_events\n",
    "\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "        # -------------- Final Output Dictionary --------------\n",
    "        return {\n",
    "            \"Model\": model_name,\n",
    "            \"C_index\": np.nan,\n",
    "            \"C_index_IPCW\": np.nan,\n",
    "            \"IBS\": np.nan,\n",
    "            \"AUC@15\": auc_15,\n",
    "            \"Calibration\": calibration,\n",
    "            \"Accuracy\": accuracy,\n",
    "            \"AUC\": roc_auc,\n",
    "            \"F1\": f1,\n",
    "            \"NRI_Events\": nri_events,\n",
    "            \"NRI_Non_Events\": nri_non_events,\n",
    "            \"NRI_Total\": nri_total\n",
    "        }, y_pred_proba\n",
    "\n",
    "    except Exception as e:\n",
    "        # If something goes wrong, return all NaN metrics\n",
    "        return {\n",
    "            \"Model\": model_name,\n",
    "            \"C_index\": np.nan,\n",
    "            \"C_index_IPCW\": np.nan,\n",
    "            \"IBS\": np.nan,\n",
    "            \"AUC@15\": np.nan,\n",
    "            \"Calibration\": np.nan,\n",
    "            \"Accuracy\": np.nan,\n",
    "            \"AUC\": np.nan,\n",
    "            \"F1\": np.nan,\n",
    "            \"NRI_Events\": np.nan,\n",
    "            \"NRI_Non_Events\": np.nan,\n",
    "            \"NRI_Total\": np.nan\n",
    "        }, np.array([])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206d5c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------- Main Evaluation Loop -----------------\n",
    "\n",
    "\n",
    "all_results = []\n",
    "baseline_probabilities = {}  # Stores baseline model probabilities for NRI calculation\n",
    "\n",
    "print(\"Starting comprehensive model evaluation...\")\n",
    "\n",
    "for method, df in datasets.items():\n",
    "    print(f\"\\nMETHOD: {method.upper()}\")\n",
    "\n",
    "    # ----------------- Train / Test Splitting -----------------\n",
    "    train_df, test_df = train_test_split(\n",
    "        df,\n",
    "        test_size=0.3,\n",
    "        random_state=42,\n",
    "        stratify=df[EVT]   # Ensures balanced event/non-event distribution\n",
    "    )\n",
    "\n",
    "    # Dataframe for fitting survival models (lifelines format)\n",
    "    df_fit = train_df[[DUR, EVT] + X_COLS].copy()\n",
    "\n",
    "    # Assign sample weights depending on method\n",
    "    if method == \"ipcw\" and \"ipcw\" in train_df.columns:\n",
    "        df_fit[\"ipcw\"] = train_df[\"ipcw\"]\n",
    "        w_col = \"ipcw\"\n",
    "    elif method == \"discard\" and \"discard_weight\" in train_df.columns:\n",
    "        df_fit[\"discard_weight\"] = train_df[\"discard_weight\"]\n",
    "        w_col = \"discard_weight\"\n",
    "    else:\n",
    "        w_col = None\n",
    "\n",
    "    # ===================== SURVIVAL MODELS =====================\n",
    "\n",
    "    # ------ Cox Proportional Hazards ------\n",
    "    try:\n",
    "        cph = CoxPHFitter()\n",
    "        cph.fit(\n",
    "            df_fit,\n",
    "            duration_col=DUR,\n",
    "            event_col=EVT,\n",
    "            weights_col=w_col,\n",
    "            robust=True\n",
    "        )\n",
    "        res_cph = evaluate_survival_model(\"Cox PH\", cph, train_df, test_df)\n",
    "        res_cph[\"Method\"] = method\n",
    "        res_cph[\"Model_Type\"] = \"Survival\"\n",
    "        all_results.append(res_cph)\n",
    "    except Exception:\n",
    "        pass  # Continue even if Cox model fails\n",
    "\n",
    "    # ------ Weibull AFT ------\n",
    "    try:\n",
    "        aft = WeibullAFTFitter()\n",
    "        if w_col:\n",
    "            # Avoid zeros in weights for stability\n",
    "            df_fit_aft = df_fit.copy()\n",
    "            df_fit_aft[w_col] = np.maximum(df_fit_aft[w_col], 1e-6)\n",
    "            aft.fit(df_fit_aft, duration_col=DUR, event_col=EVT, weights_col=w_col)\n",
    "        else:\n",
    "            aft.fit(df_fit, duration_col=DUR, event_col=EVT)\n",
    "\n",
    "        res_aft = evaluate_survival_model(\"Weibull AFT\", aft, train_df, test_df)\n",
    "        res_aft[\"Method\"] = method\n",
    "        res_aft[\"Model_Type\"] = \"Survival\"\n",
    "        all_results.append(res_aft)\n",
    "    except Exception:\n",
    "        pass  # Continue even if AFT model fails\n",
    "\n",
    "    # ===================== CLASSIFICATION MODELS =====================\n",
    "\n",
    "    # Binary target: event occurs within T_STAR years\n",
    "    y_train = ((train_df[DUR] <= T_STAR) & (train_df[EVT] == 1)).astype(int)\n",
    "    y_test = ((test_df[DUR] <= T_STAR) & (test_df[EVT] == 1)).astype(int)\n",
    "    X_train, X_test = train_df[X_COLS], test_df[X_COLS]\n",
    "\n",
    "    # Sample weights for classification (IPCW or DISCARD)\n",
    "    sw_train = None\n",
    "    if method == \"ipcw\" and \"ipcw\" in train_df.columns:\n",
    "        sw_train = train_df[\"ipcw\"].copy()\n",
    "        # Optionally down-weight non-events to stabilize\n",
    "        sw_train[y_train == 0] = 0.1\n",
    "    elif method == \"discard\" and \"discard_weight\" in train_df.columns:\n",
    "        sw_train = train_df[\"discard_weight\"].copy()\n",
    "\n",
    "    # Define standard classifiers\n",
    "    classifiers = {\n",
    "        \"Logistic Regression\": make_pipeline(StandardScaler(), LogisticRegression(max_iter=1000, random_state=42)),\n",
    "        \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1),\n",
    "        \"SVM (RBF)\": make_pipeline(StandardScaler(), SVC(probability=True, random_state=42)),\n",
    "        \"KNN\": make_pipeline(StandardScaler(), KNeighborsClassifier(n_neighbors=25))\n",
    "    }\n",
    "\n",
    "    # Evaluate each classifier\n",
    "    for name, clf in classifiers.items():\n",
    "        try:\n",
    "            # Use baseline probabilities only for NRI comparison in non-zero methods\n",
    "            baseline_proba = baseline_probabilities.get(name, None) if method != \"zero\" else None\n",
    "\n",
    "            res_clf, y_pred_proba = evaluate_classifier(\n",
    "                name, clf, X_train, y_train, X_test, y_test,\n",
    "                sample_weight=sw_train,\n",
    "                baseline_proba=baseline_proba\n",
    "            )\n",
    "            res_clf[\"Method\"] = method\n",
    "            res_clf[\"Model_Type\"] = \"Classification\"\n",
    "            all_results.append(res_clf)\n",
    "\n",
    "            # Save baseline probabilities from ZERO method for NRI comparison\n",
    "            if method == \"zero\":\n",
    "                baseline_probabilities[name] = y_pred_proba\n",
    "\n",
    "        except Exception:\n",
    "            pass  # Continue evaluating other models even if one fails\n",
    "\n",
    "# ----------------- Save and Print Results -----------------\n",
    "res = pd.DataFrame(all_results)\n",
    "res.to_csv(\"model_evaluation_results.csv\", index=False)\n",
    "\n",
    "print(\"\\nCOMPREHENSIVE MODEL EVALUATION RESULTS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Survival Results Table\n",
    "survival_results = res[res['Model_Type'] == 'Survival'][['Model', 'Method', 'C_index', 'C_index_IPCW', 'IBS', 'AUC@15', 'Calibration']]\n",
    "if not survival_results.empty:\n",
    "    print(\"\\nSURVIVAL MODELS:\")\n",
    "    print(survival_results.round(3).to_string(index=False))\n",
    "\n",
    "# Classification Results Table\n",
    "class_results = res[res['Model_Type'] == 'Classification'][['Model', 'Method', 'Accuracy', 'AUC', 'F1', 'AUC@15', 'Calibration', 'NRI_Total']]\n",
    "if not class_results.empty:\n",
    "    print(\"\\nCLASSIFICATION MODELS:\")\n",
    "    print(class_results.round(3).to_string(index=False))\n",
    "\n",
    "print(\"\\nResults saved to 'model_evaluation_results.csv'\")\n",
    "print(\"Evaluation completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2dc546",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6f3de83a",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
