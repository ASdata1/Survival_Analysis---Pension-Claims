{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06b9d0d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Install scikit-survival package\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"scikit-survival\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53641d7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn==1.3.2 in c:\\users\\04ama\\anaconda3\\lib\\site-packages (1.3.2)\n",
      "Requirement already satisfied: scikit-survival==0.22.2 in c:\\users\\04ama\\anaconda3\\lib\\site-packages (0.22.2)\n",
      "Requirement already satisfied: numpy<2.0,>=1.17.3 in c:\\users\\04ama\\anaconda3\\lib\\site-packages (from scikit-learn==1.3.2) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\04ama\\anaconda3\\lib\\site-packages (from scikit-learn==1.3.2) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\04ama\\anaconda3\\lib\\site-packages (from scikit-learn==1.3.2) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\04ama\\anaconda3\\lib\\site-packages (from scikit-learn==1.3.2) (3.5.0)\n",
      "Requirement already satisfied: ecos in c:\\users\\04ama\\anaconda3\\lib\\site-packages (from scikit-survival==0.22.2) (2.0.14)\n",
      "Requirement already satisfied: numexpr in c:\\users\\04ama\\anaconda3\\lib\\site-packages (from scikit-survival==0.22.2) (2.8.7)\n",
      "Requirement already satisfied: osqp!=0.6.0,!=0.6.1 in c:\\users\\04ama\\anaconda3\\lib\\site-packages (from scikit-survival==0.22.2) (0.6.7.post3)\n",
      "Requirement already satisfied: pandas>=1.0.5 in c:\\users\\04ama\\anaconda3\\lib\\site-packages (from scikit-survival==0.22.2) (2.3.1)\n",
      "Requirement already satisfied: qdldl in c:\\users\\04ama\\anaconda3\\lib\\site-packages (from osqp!=0.6.0,!=0.6.1->scikit-survival==0.22.2) (0.1.7.post5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\04ama\\anaconda3\\lib\\site-packages (from pandas>=1.0.5->scikit-survival==0.22.2) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\04ama\\anaconda3\\lib\\site-packages (from pandas>=1.0.5->scikit-survival==0.22.2) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\04ama\\anaconda3\\lib\\site-packages (from pandas>=1.0.5->scikit-survival==0.22.2) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\04ama\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=1.0.5->scikit-survival==0.22.2) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "%pip install scikit-learn==1.3.2 scikit-survival==0.22.2\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from lifelines import CoxPHFitter, WeibullAFTFitter\n",
    "from lifelines.utils import concordance_index\n",
    "from sksurv.util import Surv\n",
    "from sksurv.metrics import (\n",
    "    concordance_index_ipcw,\n",
    "    integrated_brier_score,\n",
    "    brier_score,\n",
    "    cumulative_dynamic_auc\n",
    ")\n",
    "\n",
    "# Load datasets\n",
    "df_zero    = pd.read_csv(\"C:\\\\Users\\\\04ama\\\\OneDrive\\\\pension survival analysis\\\\notebooks\\\\ipcw_and_other_censoring\\\\data\\\\censoring_methods\\\\data_zero.csv\")\n",
    "df_discard = pd.read_csv(\"C:\\\\Users\\\\04ama\\\\OneDrive\\\\pension survival analysis\\\\notebooks\\\\ipcw_and_other_censoring\\\\data\\\\censoring_methods\\\\data_discard.csv\")\n",
    "df_ipcw    = pd.read_csv(\"C:\\\\Users\\\\04ama\\\\OneDrive\\\\pension survival analysis\\\\notebooks\\\\ipcw_and_other_censoring\\\\data\\\\censoring_methods\\\\data_ipcw.csv\")\n",
    "\n",
    "datasets = {\"zero\": df_zero, \"discard\": df_discard, \"ipcw\": df_ipcw}\n",
    "\n",
    "X_COLS = [\"age_at_entry\", \"income_level\", \"health_score\", \"pension_contrib_rate\"]\n",
    "DUR = \"time_to_event\"\n",
    "EVT = \"event_observed\"\n",
    "T_STAR = 15.0\n",
    "# Adjust TIMES to be within the valid follow-up range [0.04; 25.0[\n",
    "TIMES = np.linspace(1, 24, 6)  # Changed from (5, 30, 6) to (1, 24, 6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a71fee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lifelines import KaplanMeierFitter\n",
    "from sksurv.metrics import concordance_index_ipcw, integrated_brier_score, cumulative_dynamic_auc\n",
    "\n",
    "def make_surv(df):\n",
    "    return Surv.from_arrays(event=df[EVT].astype(bool), time=df[DUR])\n",
    "\n",
    "def evaluate_survival_model(model_name, model, train_df, test_df, weights=None):\n",
    "    y_tr = make_surv(train_df)\n",
    "    y_te = make_surv(test_df)\n",
    "    S_pred = model.predict_survival_function(test_df[X_COLS], times=TIMES).T.values\n",
    "    risk_scores = 1 - S_pred[:, -1]  # event risk at last time\n",
    "    c_uno = concordance_index_ipcw(y_tr, y_te, -risk_scores, tau=TIMES[-1])[0]\n",
    "    ibs = integrated_brier_score(y_tr, y_te, S_pred, TIMES)\n",
    "    auc_times, aucs = cumulative_dynamic_auc(y_tr, y_te, risk_scores, TIMES)\n",
    "    \n",
    "    # Handle case where aucs might be scalar or array\n",
    "    if np.isscalar(aucs):\n",
    "        auc_15 = float(aucs)\n",
    "    else:\n",
    "        # Find closest time to T_STAR\n",
    "        closest_idx = np.argmin(np.abs(auc_times - T_STAR))\n",
    "        auc_15 = float(aucs[closest_idx])\n",
    "    \n",
    "    return {\"Model\": model_name, \"C_index\": c_uno, \"IBS\": ibs, \"AUC@15\": auc_15}\n",
    "\n",
    "def evaluate_classifier(model_name, model, X_train, y_train, X_test, y_test, sample_weight=None):\n",
    "    \"\"\"Evaluate binary classifier\"\"\"\n",
    "    # Fit model\n",
    "    if sample_weight is not None and hasattr(model, 'fit') and 'sample_weight' in model.fit.__code__.co_varnames:\n",
    "        model.fit(X_train, y_train, sample_weight=sample_weight)\n",
    "    else:\n",
    "        model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    if hasattr(model, 'predict_proba'):\n",
    "        y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "        auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    elif hasattr(model, 'decision_function'):\n",
    "        y_pred_scores = model.decision_function(X_test)\n",
    "        auc = roc_auc_score(y_test, y_pred_scores)\n",
    "    else:\n",
    "        auc = np.nan\n",
    "    \n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    \n",
    "    return {\"Model\": model_name, \"Accuracy\": accuracy, \"AUC\": auc, \"F1\": f1}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ae76b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== METHOD: ZERO ===\n",
      "\n",
      "=== METHOD: DISCARD ===\n",
      "\n",
      "=== METHOD: DISCARD ===\n",
      "\n",
      "=== METHOD: IPCW ===\n",
      "\n",
      "=== METHOD: IPCW ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\04ama\\anaconda3\\Lib\\site-packages\\lifelines\\fitters\\coxph_fitter.py:1356: StatisticalWarning: It appears your weights are not integers, possibly propensity or sampling scores then?\n",
      "It's important to know that the naive variance estimates of the coefficients are biased. Instead a) set `robust=True` in the call to `fit`, or b) use Monte Carlo to\n",
      "estimate the variances. See paper \"Variance estimation when using inverse probability of treatment weighting (IPTW) with survival analysis\"\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Cannot save file into a non-existent directory: 'data\\results'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 56\u001b[0m\n\u001b[0;32m     53\u001b[0m         all_results\u001b[38;5;241m.\u001b[39mappend(res_clf)\n\u001b[0;32m     55\u001b[0m res \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(all_results)\n\u001b[1;32m---> 56\u001b[0m res\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/results/results.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m✅ Results saved to results.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     58\u001b[0m display(res)\n",
      "File \u001b[1;32mc:\\Users\\04ama\\anaconda3\\Lib\\site-packages\\pandas\\util\\_decorators.py:333\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    328\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    329\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    330\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    331\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    332\u001b[0m     )\n\u001b[1;32m--> 333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\04ama\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:3986\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[0;32m   3975\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_frame()\n\u001b[0;32m   3977\u001b[0m formatter \u001b[38;5;241m=\u001b[39m DataFrameFormatter(\n\u001b[0;32m   3978\u001b[0m     frame\u001b[38;5;241m=\u001b[39mdf,\n\u001b[0;32m   3979\u001b[0m     header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3983\u001b[0m     decimal\u001b[38;5;241m=\u001b[39mdecimal,\n\u001b[0;32m   3984\u001b[0m )\n\u001b[1;32m-> 3986\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m DataFrameRenderer(formatter)\u001b[38;5;241m.\u001b[39mto_csv(\n\u001b[0;32m   3987\u001b[0m     path_or_buf,\n\u001b[0;32m   3988\u001b[0m     lineterminator\u001b[38;5;241m=\u001b[39mlineterminator,\n\u001b[0;32m   3989\u001b[0m     sep\u001b[38;5;241m=\u001b[39msep,\n\u001b[0;32m   3990\u001b[0m     encoding\u001b[38;5;241m=\u001b[39mencoding,\n\u001b[0;32m   3991\u001b[0m     errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m   3992\u001b[0m     compression\u001b[38;5;241m=\u001b[39mcompression,\n\u001b[0;32m   3993\u001b[0m     quoting\u001b[38;5;241m=\u001b[39mquoting,\n\u001b[0;32m   3994\u001b[0m     columns\u001b[38;5;241m=\u001b[39mcolumns,\n\u001b[0;32m   3995\u001b[0m     index_label\u001b[38;5;241m=\u001b[39mindex_label,\n\u001b[0;32m   3996\u001b[0m     mode\u001b[38;5;241m=\u001b[39mmode,\n\u001b[0;32m   3997\u001b[0m     chunksize\u001b[38;5;241m=\u001b[39mchunksize,\n\u001b[0;32m   3998\u001b[0m     quotechar\u001b[38;5;241m=\u001b[39mquotechar,\n\u001b[0;32m   3999\u001b[0m     date_format\u001b[38;5;241m=\u001b[39mdate_format,\n\u001b[0;32m   4000\u001b[0m     doublequote\u001b[38;5;241m=\u001b[39mdoublequote,\n\u001b[0;32m   4001\u001b[0m     escapechar\u001b[38;5;241m=\u001b[39mescapechar,\n\u001b[0;32m   4002\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[0;32m   4003\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\04ama\\anaconda3\\Lib\\site-packages\\pandas\\io\\formats\\format.py:1014\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[1;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[0;32m    993\u001b[0m     created_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    995\u001b[0m csv_formatter \u001b[38;5;241m=\u001b[39m CSVFormatter(\n\u001b[0;32m    996\u001b[0m     path_or_buf\u001b[38;5;241m=\u001b[39mpath_or_buf,\n\u001b[0;32m    997\u001b[0m     lineterminator\u001b[38;5;241m=\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1012\u001b[0m     formatter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfmt,\n\u001b[0;32m   1013\u001b[0m )\n\u001b[1;32m-> 1014\u001b[0m csv_formatter\u001b[38;5;241m.\u001b[39msave()\n\u001b[0;32m   1016\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[0;32m   1017\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[1;32mc:\\Users\\04ama\\anaconda3\\Lib\\site-packages\\pandas\\io\\formats\\csvs.py:251\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    247\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;124;03mCreate the writer & save.\u001b[39;00m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;66;03m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[1;32m--> 251\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_handle(\n\u001b[0;32m    252\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilepath_or_buffer,\n\u001b[0;32m    253\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    254\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    255\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merrors,\n\u001b[0;32m    256\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompression,\n\u001b[0;32m    257\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstorage_options,\n\u001b[0;32m    258\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter \u001b[38;5;241m=\u001b[39m csvlib\u001b[38;5;241m.\u001b[39mwriter(\n\u001b[0;32m    261\u001b[0m         handles\u001b[38;5;241m.\u001b[39mhandle,\n\u001b[0;32m    262\u001b[0m         lineterminator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    267\u001b[0m         quotechar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquotechar,\n\u001b[0;32m    268\u001b[0m     )\n\u001b[0;32m    270\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save()\n",
      "File \u001b[1;32mc:\\Users\\04ama\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:749\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    747\u001b[0m \u001b[38;5;66;03m# Only for write methods\u001b[39;00m\n\u001b[0;32m    748\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode \u001b[38;5;129;01mand\u001b[39;00m is_path:\n\u001b[1;32m--> 749\u001b[0m     check_parent_directory(\u001b[38;5;28mstr\u001b[39m(handle))\n\u001b[0;32m    751\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compression:\n\u001b[0;32m    752\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m compression \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzstd\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    753\u001b[0m         \u001b[38;5;66;03m# compression libraries do not like an explicit text-mode\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\04ama\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:616\u001b[0m, in \u001b[0;36mcheck_parent_directory\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m    614\u001b[0m parent \u001b[38;5;241m=\u001b[39m Path(path)\u001b[38;5;241m.\u001b[39mparent\n\u001b[0;32m    615\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m parent\u001b[38;5;241m.\u001b[39mis_dir():\n\u001b[1;32m--> 616\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[38;5;124mrf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot save file into a non-existent directory: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparent\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mOSError\u001b[0m: Cannot save file into a non-existent directory: 'data\\results'"
     ]
    }
   ],
   "source": [
    "all_results = []\n",
    "\n",
    "\n",
    "\n",
    "for method, df in datasets.items():\n",
    "    print(f\"\\n=== METHOD: {method.upper()} ===\")\n",
    "    train_df, test_df = train_test_split(df, test_size=0.3, random_state=42, stratify=df[EVT] if method != \"discard\" else None)\n",
    "\n",
    "    df_fit = train_df[[DUR, EVT] + X_COLS].copy()\n",
    "    # ------------- SURVIVAL MODELS -------------\n",
    "    if method == \"ipcw\" and \"ipcw\" in train_df.columns:\n",
    "        df_fit[\"ipcw\"] = train_df[\"ipcw\"]\n",
    "        w_col = \"ipcw\"\n",
    "    else:\n",
    "        w_col = None\n",
    "\n",
    "    # Cox PH\n",
    "    cph = CoxPHFitter()\n",
    "    cph.fit(df_fit, duration_col=DUR, event_col=EVT,\n",
    "            weights_col=w_col if w_col else None)\n",
    "    res_cph = evaluate_survival_model(\"CoxPH\", cph, train_df, test_df)\n",
    "    res_cph[\"Method\"] = method\n",
    "    all_results.append(res_cph)\n",
    "\n",
    "    # Weibull AFT (doesn't support weights well, so fit without weights)\n",
    "    aft = WeibullAFTFitter()\n",
    "    aft.fit(df_fit[[DUR, EVT] + X_COLS], duration_col=DUR, event_col=EVT)\n",
    "    res_aft = evaluate_survival_model(\"WeibullAFT\", aft, train_df, test_df)\n",
    "    res_aft[\"Method\"] = method\n",
    "    all_results.append(res_aft)\n",
    "\n",
    "    # ------------- CLASSIFIERS -------------\n",
    "    # Convert to binary outcome: event occurred by t*?\n",
    "    y_train = ((train_df[DUR] <= T_STAR) & (train_df[EVT] == 1)).astype(int)\n",
    "    y_test  = ((test_df[DUR] <= T_STAR) & (test_df[EVT] == 1)).astype(int)\n",
    "    X_train, X_test = train_df[X_COLS], test_df[X_COLS]\n",
    "\n",
    "    sw_train = None\n",
    "    if method == \"ipcw\" and \"ipcw\" in train_df.columns:\n",
    "        sw_train = train_df[\"ipcw\"].copy()\n",
    "        sw_train[y_train == 0] = 0  # only count events\n",
    "\n",
    "    classifiers = {\n",
    "        \"Logistic Regression\": make_pipeline(StandardScaler(), LogisticRegression(max_iter=1000)),\n",
    "        \"Random Forest\": RandomForestClassifier(n_estimators=400, random_state=42),\n",
    "        \"SVM (RBF)\": make_pipeline(StandardScaler(), SVC(probability=True, random_state=42)),\n",
    "        \"KNN\": make_pipeline(StandardScaler(), KNeighborsClassifier(n_neighbors=25))\n",
    "    }\n",
    "\n",
    "    for name, clf in classifiers.items():\n",
    "        res_clf = evaluate_classifier(name, clf, X_train, y_train, X_test, y_test, sample_weight=sw_train)\n",
    "        res_clf[\"Method\"] = method\n",
    "        all_results.append(res_clf)\n",
    "\n",
    "res = pd.DataFrame(all_results)\n",
    "res.to_csv(\"results.csv\", index=False)\n",
    "print(\"\\n✅ Results saved to results.csv\")\n",
    "display(res)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f3de83a",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
